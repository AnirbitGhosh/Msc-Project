{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from abc import abstractmethod\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestep_embedding(timesteps, dim, max_period=1000):\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(\n",
    "        -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
    "    ).to(device=timesteps.device)\n",
    "    args = timesteps[:, None].float() * freqs[None]\n",
    "    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "    if dim % 2:\n",
    "        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "    return embedding\n",
    "\n",
    "class TimestepBlock(nn.Module):\n",
    "    @abstractmethod\n",
    "    def forward(self, x, emb):\n",
    "        \"\"\"\n",
    "        Apply the module to `x` given `emb` timestep embeddings.\n",
    "        \"\"\"\n",
    "\n",
    "class TimestepEmbedSequential(nn.Sequential, TimestepBlock):\n",
    "    \"\"\"\n",
    "    A sequential module that passes timestep embeddings to the children that\n",
    "    support it as an extra input.\n",
    "    \"\"\"\n",
    "    def forward(self, x, t_emb, c_emb, mask):\n",
    "        for layer in self:\n",
    "            if(isinstance(layer, TimestepBlock)):\n",
    "                x = layer(x, t_emb, c_emb, mask)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "            return x\n",
    "\n",
    "def norm_layer(channels):\n",
    "    return nn.GroupNorm(32, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(TimestepBlock):\n",
    "    def __init__(self, in_channels, out_channels, time_channels, class_channels, dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            norm_layer(in_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.time_emb = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.class_emb = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(class_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            norm_layer(out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "    \n",
    "    def forward(self, x, t, c, mask):\n",
    "        \"\"\"\n",
    "        `x` has shape `[batch_size, in_dim, height, width]`\n",
    "        `t` has shape `[batch_size, time_dim]`\n",
    "        `c` has shape `[batch_size, class_dim]`\n",
    "        `mask` has shape `[batch_size, ]`\n",
    "        \"\"\"\n",
    "        h = self.conv1(x)\n",
    "        emb_t = self.time_emb(t)\n",
    "        emb_c = self.class_emb(c)*mask[:, None]\n",
    "        h += (emb_t[:, :, None, None] + emb_c[:, :, None, None])\n",
    "        h = self.conv2(h)\n",
    "        \n",
    "        return h + self.shortcut(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, channels, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        assert channels % num_heads == 0\n",
    "        \n",
    "        self.norm = norm_layer(channels)\n",
    "        self.qkv = nn.Conv2d(channels, channels * 3, kernel_size=1, bias=False)\n",
    "        self.proj = nn.Conv2d(channels, channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        qkv = self.qkv(self.norm(x))\n",
    "        q, k, v = qkv.reshape(B *  self.num_heads, -1, H * W).chunk(3, dim=1)\n",
    "        scale = 1. / math.sqrt(math.sqrt(C // self.num_heads))\n",
    "        attn = torch.einsum(\"bct,bcs->bts\", q * scale, k * scale)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        h = torch.einsum(\"bts,bcs->bct\", attn, v)\n",
    "        h = h.reshape(B, -1, H, W)\n",
    "        h = self.proj(h)\n",
    "        return h + x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    def __init__(self, channels, use_conv):\n",
    "        super().__init__()\n",
    "        self.use_conv = use_conv\n",
    "        if use_conv:\n",
    "            self.conv = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "        if self.use_conv:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, channels, use_conv):\n",
    "        super().__init__()\n",
    "        self.use_conv = use_conv\n",
    "        if use_conv:\n",
    "            self.op = nn.Conv2d(channels, channels, kernel_size=3, padding=1, stride=2)\n",
    "        else:\n",
    "            self.op = nn.AvgPool2d(stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.op(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels=2,\n",
    "                 model_channels=128,\n",
    "                 out_channels=2,\n",
    "                 num_res_blocks=2, \n",
    "                 attention_resolutions=(8, 16),\n",
    "                 dropout=0,\n",
    "                 channel_mult=(1, 2, 2, 2),\n",
    "                 conv_resample=True,\n",
    "                 num_heads=4, \n",
    "                 class_num=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.model_channels = model_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.attention_resolutions = attention_resolutions,\n",
    "        self.dropout = dropout\n",
    "        self.channel_mult = channel_mult,\n",
    "        self.conv_resample = conv_resample\n",
    "        self.num_heads = num_heads\n",
    "        self.class_num = class_num\n",
    "        \n",
    "        # time embedding\n",
    "        time_emb_dim = model_channels*4\n",
    "        self.time_emb = nn.Sequential(\n",
    "            nn.Linear(model_channels, time_emb_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim)\n",
    "        )\n",
    "        \n",
    "        # conditional (class) embedding\n",
    "        class_emb_dim = model_channels\n",
    "        self.class_emb = nn.Embedding(class_num, class_emb_dim)\n",
    "        \n",
    "        # down blocks\n",
    "        self.down_blocks = nn.ModuleList([\n",
    "            TimestepEmbedSequential(nn.Conv2d(in_channels, model_channels, kernel_size=3, padding=1))\n",
    "        ])\n",
    "        down_block_channels = [model_channels]\n",
    "        ch = model_channels\n",
    "        ds = 1\n",
    "        for level, mult in enumerate(channel_mult):\n",
    "            for _ in range(num_res_blocks):\n",
    "                layers = [ResidualBlock(ch, model_channels*mult, time_emb_dim, class_emb_dim, dropout)]\n",
    "                ch = model_channels*mult\n",
    "                if ds in attention_resolutions:\n",
    "                    layers.append(AttentionBlock(ch, num_heads))\n",
    "                self.down_blocks.append(TimestepEmbedSequential(*layers))\n",
    "                down_block_channels.append(ch)\n",
    "            if level != len(channel_mult)-1:\n",
    "                self.down_blocks.append(TimestepEmbedSequential(DownSample(ch, conv_resample)))\n",
    "                down_block_channels.append(ch)\n",
    "                ds *= 2\n",
    "        \n",
    "        # middle blocks\n",
    "        self.middle_blocks = TimestepEmbedSequential(\n",
    "            ResidualBlock(ch, ch, time_emb_dim, class_emb_dim, dropout),\n",
    "            AttentionBlock(ch, num_heads),\n",
    "            ResidualBlock(ch, ch, time_emb_dim, class_emb_dim, dropout)\n",
    "        )\n",
    "        \n",
    "        # up blocks\n",
    "        self.up_blocks = nn.ModuleList([])\n",
    "        for level, mult in enumerate(channel_mult[::-1]):\n",
    "            for i in range(num_res_blocks+1):\n",
    "                layers = [\n",
    "                    ResidualBlock(ch+down_block_channels.pop(), model_channels*mult, time_emb_dim, class_emb_dim, dropout)\n",
    "                ]\n",
    "                ch = model_channels*mult\n",
    "                if ds in attention_resolutions:\n",
    "                    layers.append(AttentionBlock(ch, num_heads))\n",
    "                if level != len(channel_mult)-1 and i == num_res_blocks:\n",
    "                    layers.append(UpSample(ch, conv_resample))\n",
    "                    ds //=2\n",
    "                self.up_blocks.append(TimestepEmbedSequential(*layers))\n",
    "                \n",
    "        self.out = nn.Sequential(\n",
    "            norm_layer(ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(ch, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, timesteps, c, mask):\n",
    "        \"\"\"\n",
    "        Apply the model to an input batch.\n",
    "        :param x: an [N x C x H x W] Tensor of inputs.\n",
    "        :param timesteps: a 1-D batch of timesteps.\n",
    "        :param c: a 1-D batch of classes.\n",
    "        :param mask: a 1-D batch of conditioned/unconditioned.\n",
    "        :return: an [N x C x ...] Tensor of outputs.\n",
    "        \"\"\"\n",
    "        hs = []\n",
    "        # time step and class embedding\n",
    "        t_emb = self.time_emb(timestep_embedding(timesteps, dim=self.model_channels))\n",
    "        c_emb = self.class_emb(c)\n",
    "        \n",
    "        # down step\n",
    "        h = x\n",
    "        for module in self.down_blocks:\n",
    "            h = module(h, t_emb, c_emb, mask)\n",
    "            hs.append(h)\n",
    "        \n",
    "        # mid stage\n",
    "        h = self.middle_blocks(h, t_emb, c_emb, mask)\n",
    "        \n",
    "        # up stage\n",
    "        for module in self.up_blocks:\n",
    "            cat_in = torch.cat([h, hs.pop()], dim=1)\n",
    "            h = module(cat_in, t_emb, c_emb, mask)\n",
    "            \n",
    "        return self.out(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta schedule\n",
    "def linear_beta_schedule(timesteps):\n",
    "    scale = 1000 / timesteps\n",
    "    beta_start = scale * 0.0001\n",
    "    beta_end = scale * 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps, dtype=torch.float64)\n",
    "\n",
    "def sigmoid_beta_schedule(timesteps):\n",
    "    betas = torch.linspace(-6, 6, timesteps)\n",
    "    betas = torch.sigmoid(betas) / (betas.max() - betas.min()) * (0.02 - betas.min()) / 10\n",
    "    return betas\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps, dtype=torch.float64)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    def __init__(\n",
    "        self,\n",
    "        timesteps = 1000,\n",
    "        beta_schedule = 'linear',\n",
    "    ):\n",
    "        self.timesteps = timesteps\n",
    "        \n",
    "        if beta_schedule == 'linear':\n",
    "            betas = linear_beta_schedule(timesteps)\n",
    "        elif beta_schedule == 'cosine':\n",
    "            betas = cosine_beta_schedule(timesteps)\n",
    "        elif beta_schedule == 'sigmoid':\n",
    "            betas = sigmoid_beta_schedule(timesteps)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown beta schedule {beta_schedule}')\n",
    "        \n",
    "        self.betas = betas\n",
    "        \n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.)\n",
    "        \n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "        self.log_one_minus_alphas_cumprod = torch.log(1.0 - self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod)\n",
    "        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod - 1)\n",
    "        \n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        self.posterior_variance = (\n",
    "            self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "        self.posterior_log_variance_clipped = torch.log(\n",
    "            torch.cat([self.posterior_variance[1:2], self.posterior_variance[1:]])\n",
    "        )\n",
    "        \n",
    "        self.posterior_mean_coef1 = (\n",
    "            self.betas * torch.sqrt(self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "        self.posterior_mean_coef2 = (\n",
    "            (1.0 - self.alphas_cumprod_prev) * torch.sqrt(self.alphas) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "    \n",
    "    # get the param of given timestep t\n",
    "    def _extract(self, a, t, x_shape):\n",
    "        batch_size = t.shape[0]\n",
    "        out = a.to(t.device).gather(0, t).float()\n",
    "        out = out.reshape(batch_size, *((1,) * (len(x_shape) - 1)))\n",
    "        return out\n",
    "    \n",
    "    # forward diffusion : q(x_t | x_0)\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        \n",
    "        sqrt_alphas_cumprod_t = self._extract(self.sqrt_alphas_cumprod, t, x_start.shape)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "        \n",
    "        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "    \n",
    "    # mean and variance of q(x_t | x_0)\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        mean = self._extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "        variance = self._extract(1.0 - self.alphas_cumprod, t, x_start.shape)\n",
    "        log_variance = self._extract(self.log_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "        return mean, variance, log_variance\n",
    "    \n",
    "    # mean and variance of diffusion posterior: q(x_{t-1} | x_t, x_0)\n",
    "    def q_posterior_mean_variance(self, x_start, x_t, t):\n",
    "        posterior_mean = (\n",
    "            self._extract(self.posterior_mean_coef1, t, x_t.shape) * x_start + self._extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = self._extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = self._extract(self.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "    \n",
    "    # compute x_0 from x_t and pred noise: reverse of q_sample\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            self._extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "    \n",
    "    # compute predicted mean and variance of p(x_{t-1} | x_t) \n",
    "    def p_mean_variance(self, model, x_t, t, c, w, clip_denoised=True):\n",
    "        device = next(model.parameters()).device\n",
    "        batch_size = x_t.shape[0]\n",
    "        \n",
    "        # noise prediction from model\n",
    "        pred_noise_c = model(x_t, t, c, torch.ones(batch_size).int().to(device))\n",
    "        pred_noise_none = model(x_t, t, c, torch.zeros(batch_size).int().to(device))\n",
    "        pred_noise = (1 + w) * pred_noise_c - w * pred_noise_none\n",
    "        \n",
    "        # get predicted x_0\n",
    "        x_recon = self.predict_start_from_noise(x_t, t, pred_noise)\n",
    "        if clip_denoised:\n",
    "            x_recon = torch.clamp(x_recon, min=-1., max=1.)\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior_mean_variance(x_recon, x_t, t)\n",
    "        \n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "    \n",
    "    # denoise step: sample x_{t-1} from x_t and pred noise\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, model, x_t, t, c, w, clip_denoised=True):\n",
    "        # pred mean and variance\n",
    "        model_mean, _, model_log_varaince = self.p_mean_variance(model, x_t, t, c, w, clip_denoised=clip_denoised)\n",
    "        \n",
    "        noise = torch.randn_like(x_t)\n",
    "        # no noise when t = 0 \n",
    "        nonzero_mask = ((t != 0).float().view(-1, *([1] * (len(x_t.shape) - 1))))\n",
    "        # compute x_{t-1}\n",
    "        pred_img = model_mean + nonzero_mask * (0.5 * model_log_varaince).exp() * noise\n",
    "        return pred_img\n",
    "    \n",
    "    # denoise : reverse diffusion\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, model, shape, n_class=10, w=2, mode='random', clip_denoised=True):\n",
    "        batch_size = shape[0]\n",
    "        device = next(model.parameters()).device\n",
    "        \n",
    "        # generate labels\n",
    "        if mode == 'random':\n",
    "            cur_y = torch.randint(0, n_class, (batch_size,)).to(device)\n",
    "        elif mode == 'all':\n",
    "            if batch_size%n_class != 0:\n",
    "                batch_size = n_class\n",
    "                print('change batch size to ', n_class)\n",
    "            cur_y = torch.tensor([x for x in range(n_class)] * (batch_size//n_class), d_type=torch.long).to(device)\n",
    "        else:\n",
    "            cur_y = torch.ones(batch_size).long().to(device)*int(mode)\n",
    "        \n",
    "        # start from pure noise\n",
    "        imgs = torch.randn(shape, device=device)\n",
    "        imgs = []\n",
    "        for i in tqdm(reversed(range(0, self.timesteps)), desc='sampling loop time step', total=self.timesteps):\n",
    "            img = self.p_sample(model, img, torch.full((batch_size, ), i, device=device, dtype=torch.long), cur_y, w, clip_denoised)\n",
    "            imgs.append(img.cpu().numpy())\n",
    "        return imgs\n",
    "    \n",
    "    # sample new images\n",
    "    @torch.no_grad\n",
    "    def sample(self, model, image_size, batch_size=8, channels=3, n_class=10, w=2, mode='random', clip_denoised=True):\n",
    "        return self.p_sample_loop(model, (batch_size, channels, image_size, image_size), n_class, w, model, clip_denoised)\n",
    "    \n",
    "    \n",
    "    # use ddim to sample\n",
    "    @torch.no_grad()\n",
    "    def ddim_sample(\n",
    "        self,\n",
    "        model,\n",
    "        image_size,\n",
    "        batch_size=8,\n",
    "        channels=3,\n",
    "        ddim_timesteps=50,\n",
    "        n_class = 10,\n",
    "        w = 2,\n",
    "        mode= 'random',\n",
    "        ddim_discr_method=\"uniform\",\n",
    "        ddim_eta=0.0,\n",
    "        clip_denoised=True):\n",
    "        \n",
    "        # make ddim timestep sequence\n",
    "        if ddim_discr_method == 'uniform':\n",
    "            c = self.timesteps // ddim_timesteps\n",
    "            ddim_timestep_seq = np.asarray(list(range(0, self.timesteps, c)))\n",
    "        elif ddim_discr_method == 'quad':\n",
    "            ddim_timestep_seq = (\n",
    "                (np.linspace(0, np.sqrt(self.timesteps * .8), ddim_timesteps)) ** 2\n",
    "            ).astype(int)\n",
    "        else:\n",
    "            raise NotImplementedError(f'There is no ddim discretization method called \"{ddim_discr_method}\"')\n",
    "        # add one to get the final alpha values right (the ones from first scale to data during sampling)\n",
    "        ddim_timestep_seq = ddim_timestep_seq + 1\n",
    "        # previous sequence\n",
    "        ddim_timestep_prev_seq = np.append(np.array([0]), ddim_timestep_seq[:-1])\n",
    "        \n",
    "        device = next(model.parameters()).device\n",
    "        \n",
    "        # generate labels\n",
    "        if mode == 'random':\n",
    "            cur_y = torch.randint(0, n_class, (batch_size,)).to(device)\n",
    "        elif mode == 'all':\n",
    "            if batch_size%n_class!=0:\n",
    "                batch_size = n_class\n",
    "                print('change batch_size to', n_class)\n",
    "            cur_y = torch.tensor([x for x in range(n_class)]*(batch_size//n_class), dtype=torch.long).to(device)\n",
    "        else:\n",
    "            cur_y = torch.ones(batch_size).long().to(device)*int(mode)\n",
    "        \n",
    "        # start from pure noise (for each example in the batch)\n",
    "        sample_img = torch.randn((batch_size, channels, image_size, image_size), device=device)\n",
    "        seq_img = [sample_img.cpu().numpy()]   \n",
    "        \n",
    "        for i in tqdm(reversed(range(0, ddim_timesteps)), desc='sampling loop time step', total=ddim_timesteps):\n",
    "            t = torch.full((batch_size,), ddim_timestep_seq[i], device=device, dtype=torch.long)\n",
    "            prev_t = torch.full((batch_size,), ddim_timestep_prev_seq[i], device=device, dtype=torch.long)\n",
    "            \n",
    "            # 1. get current and previous alpha_cumprod\n",
    "            alpha_cumprod_t = self._extract(self.alphas_cumprod, t, sample_img.shape)\n",
    "            alpha_cumprod_t_prev = self._extract(self.alphas_cumprod, prev_t, sample_img.shape)\n",
    "    \n",
    "            # 2. predict noise using model\n",
    "            pred_noise_c = model(sample_img, t, cur_y, torch.ones(batch_size).int().cuda())\n",
    "            pred_noise_none = model(sample_img, t, cur_y, torch.zeros(batch_size).int().cuda())\n",
    "            pred_noise = (1+w)*pred_noise_c - w*pred_noise_none\n",
    "            \n",
    "            # 3. get the predicted x_0\n",
    "            pred_x0 = (sample_img - torch.sqrt((1. - alpha_cumprod_t)) * pred_noise) / torch.sqrt(alpha_cumprod_t)\n",
    "            if clip_denoised:\n",
    "                pred_x0 = torch.clamp(pred_x0, min=-1., max=1.)\n",
    "            \n",
    "            # 4. compute variance: \"sigma_t(η)\" -> see formula (16)\n",
    "            # σ_t = sqrt((1 − α_t−1)/(1 − α_t)) * sqrt(1 − α_t/α_t−1)\n",
    "            sigmas_t = ddim_eta * torch.sqrt(\n",
    "                (1 - alpha_cumprod_t_prev) / (1 - alpha_cumprod_t) * (1 - alpha_cumprod_t / alpha_cumprod_t_prev))\n",
    "            \n",
    "            # 5. compute \"direction pointing to x_t\" of formula (12)\n",
    "            pred_dir_xt = torch.sqrt(1 - alpha_cumprod_t_prev - sigmas_t**2) * pred_noise\n",
    "            \n",
    "            # 6. compute x_{t-1} of formula (12)\n",
    "            x_prev = torch.sqrt(alpha_cumprod_t_prev) * pred_x0 + pred_dir_xt + sigmas_t * torch.randn_like(sample_img)\n",
    "\n",
    "            sample_img = x_prev\n",
    "            if mode == 'all':\n",
    "                seq_img.append(sample_img.cpu().numpy())\n",
    "            \n",
    "        if mode == 'all':\n",
    "            return seq_img\n",
    "        else:\n",
    "            return sample_img.cpu().numpy()\n",
    "    \n",
    "    # compute train losses\n",
    "    def train_losses(self, model, x_start, t, c, mask_c):\n",
    "        # generate random noise\n",
    "        noise = torch.randn_like(x_start)\n",
    "        # get x_t\n",
    "        x_noisy = self.q_sample(x_start, t, noise=noise)\n",
    "        predicted_noise = model(x_noisy, t, c, mask_c)\n",
    "        loss = F.mse_loss(noise, predicted_noise)\n",
    "        return loss     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalImageDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, conditional_offset=5):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.conditional_offset = conditional_offset\n",
    "        self.data = []\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        files = sorted([os.path.join(self.data_dir, f) for f in os.listdir(self.data_dir) if f.endswith('.mpy')])\n",
    "        for file in files:\n",
    "            with open(file, 'rb') as f:\n",
    "                images = pickle.load(f)\n",
    "                if isinstance(images, list):\n",
    "                    images = np.array(images)\n",
    "                self.data.append(images)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(images) for images in self.data) - len(self.data) * self.conditional_offset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        collection_idx, image_idx = self._get_indices(idx)\n",
    "        image = self.data[collection_idx][image_idx]\n",
    "        cond_image = self.data[collection_idx][image_idx - self.conditional_offset]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            cond_image = self.transform(cond_image)\n",
    "\n",
    "        return image, cond_image\n",
    "\n",
    "    def _get_indices(self, idx):\n",
    "        cumulative_length = 0\n",
    "        for collection_idx, images in enumerate(self.data):\n",
    "            collection_length = len(images) - self.conditional_offset\n",
    "            if idx < cumulative_length + collection_length:\n",
    "                return collection_idx, idx - cumulative_length + self.conditional_offset\n",
    "            cumulative_length += collection_length\n",
    "        raise IndexError(f\"Index {idx} out of range\")\n",
    "\n",
    "DATA_DIR = \"C:/Users/Anirbit/Desktop/MSc/Ind Project/Msc-Project/data/bin_frames\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "burn_data = ConditionalImageDataset(DATA_DIR, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "def plot_random_sample(dataset):\n",
    "    # Get a random index\n",
    "    # random_idx = random.randint(0, len(dataset) - 1)\n",
    "    random_idx = 30\n",
    "    \n",
    "    \n",
    "    # Get the image and conditional image\n",
    "    image, cond_image = dataset[random_idx]\n",
    "    \n",
    "    # Convert to numpy arrays for plotting\n",
    "    image = image.numpy().transpose(1, 2, 0)  # Transpose from (C, H, W) to (H, W, C)\n",
    "    cond_image = cond_image.numpy().transpose(1, 2, 0)  # Transpose from (C, H, W) to (H, W, C)\n",
    "    \n",
    "    # Denormalize the images\n",
    "    image = (image * 0.5 + 0.5).clip(0, 1)\n",
    "    cond_image = (cond_image * 0.5 + 0.5).clip(0, 1)\n",
    "    \n",
    "    # Plot the images\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    axs[0].imshow(image, cmap='gray')\n",
    "    axs[0].set_title(\"Image\")\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    axs[1].imshow(cond_image, cmap='gray')\n",
    "    axs[1].set_title(\"Conditional Image\")\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Assuming dataset is already created\n",
    "plot_random_sample(burn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (time_emb): Sequential(\n",
       "    (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=384, out_features=384, bias=True)\n",
       "  )\n",
       "  (class_emb): Embedding(10, 96)\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(1, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x TimestepEmbedSequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (time_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=384, out_features=96, bias=True)\n",
       "        )\n",
       "        (class_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=96, out_features=96, bias=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): DownSample(\n",
       "        (op): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (time_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "        )\n",
       "        (class_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=96, out_features=192, bias=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (time_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "        )\n",
       "        (class_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=96, out_features=192, bias=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): DownSample(\n",
       "        (op): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7-8): 2 x TimestepEmbedSequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (time_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "        )\n",
       "        (class_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=96, out_features=192, bias=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_blocks): TimestepEmbedSequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (time_emb): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "      )\n",
       "      (class_emb): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=96, out_features=192, bias=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (shortcut): Identity()\n",
       "    )\n",
       "    (1): AttentionBlock(\n",
       "      (norm): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "      (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (proj): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (time_emb): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "      )\n",
       "      (class_emb): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=96, out_features=192, bias=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (shortcut): Identity()\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (time_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "        )\n",
       "        (class_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=96, out_features=192, bias=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (time_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "        )\n",
       "        (class_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=96, out_features=192, bias=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3-4): 2 x TimestepEmbedSequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (time_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "        )\n",
       "        (class_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=96, out_features=192, bias=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): GroupNorm(32, 288, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(288, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (time_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "        )\n",
       "        (class_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=96, out_features=192, bias=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): GroupNorm(32, 288, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(288, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (time_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=384, out_features=96, bias=True)\n",
       "        )\n",
       "        (class_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=96, out_features=96, bias=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7-8): 2 x TimestepEmbedSequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (time_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=384, out_features=96, bias=True)\n",
       "        )\n",
       "        (class_emb): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=96, out_features=96, bias=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(96, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "timesteps = 500\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# MNIST DATA\n",
    "dataset = datasets.MNIST(root='./dataset/mnist', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Unet(\n",
    "    in_channels=1,\n",
    "    model_channels=96,\n",
    "    out_channels=1,\n",
    "    channel_mult=(1, 2, 2),\n",
    "    attention_resolutions=[],\n",
    "    class_num=10\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABOwAAAEACAYAAAAA++nbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABS6UlEQVR4nO39dZxV9f73/7+GHDokhQHpFqRGGiREkJKQRpQGQaREQEoQFOluJBQEpBFpUEnpDgnpbhhqf/84P/kcfvp+LuQMh8V1Hvfb7bpd18VjnrCZ2WvttRdznKBAIBAwAAAAAAAAAL4Q4Xk/AAAAAAAAAAD/hxt2AAAAAAAAgI9www4AAAAAAADwEW7YAQAAAAAAAD7CDTsAAAAAAADAR7hhBwAAAAAAAPgIN+wAAAAAAAAAH+GGHQAAAAAAAOAj3LADAAAAAAAAfIQbdgAAAAAAAICPcMPOx3799Vfr1q2bXblyJdx+z3nz5lnOnDktODjYUqRIYV27drX79++H2+8PQAvv43r69OlWu3ZtS5cunQUFBVnRokWdHxsWFmYdOnSwl19+2aJFi2ahoaG2dOlS5+MsWLCgRY8e3ZIkSWItW7a0GzduhMtjBv5Xhffx37p1a8uZM6fFjx/fokePbpkyZbJu3br97bHK8Q88f8/i2v5Phw8ftuDgYAsKCrLNmzf/pV+5csUaNWpkCRMmtBgxYlixYsVsy5Ytf/t78X4BeDae5zlg6dKlj17b48WLZ1WqVLGjR4/+5eNu3LhhH330kSVPntyiRo1qmTJlshEjRoT748WT4Yadj/3666/WvXv3cDugFy9ebBUrVrS4cePakCFDrGLFivb555/bhx9+GC6/PwBv4X1cjxgxwubOnWshISEWL148+bHvvfee9e/f32rVqmWDBg2yiBEjWpkyZeznn39+7OO2bdtmxYsXt1u3bln//v2tQYMGNnr0aKtatWq4PGbgf1V4H/+bNm2yQoUKWffu3W3QoEFWrFgx69Onj5UuXdoePnz42Mdy/APPX3ifA/5d69atLVKkSH/bHj58aGXLlrVp06ZZixYt7Msvv7Rz585Z0aJF7eDBg499LO8XgGfneZ0DFixYYKVLl7awsDDr06ePtWnTxlavXm0FCxa08+fPP/q4Bw8e2JtvvmkjRoywatWq2cCBAy1DhgzWrFkz6927d7g/ZjyBAHzrq6++CphZ4MiRI+Hy+2XOnDmQPXv2wL179x79WqdOnQJBQUGBvXv3hsufAUAL7+P6+PHjgQcPHgQCgUAgS5YsgSJFivztx23YsCFgZoGvvvrq0a/dvn07kCZNmkC+fPke+9i33norkDRp0sDVq1cf/dqYMWMCZhZYsmRJuDxu4H9ReB//f6dfv34BMwusW7fu0a9x/AP+8KzOAT/++GMgSpQogc6dOwfMLLBp06bH+vTp0wNmFvj+++8f/dq5c+cCcePGDdSoUeOxj+X9AvDsPK9zQObMmQNp06YNhIWFPfq1bdu2BSJEiBD4+OOPH/3ajBkzAmYWGDdu3GP7ypUrB4KDgwNnz54N18cNb3yHnU9169bN2rVrZ2ZmqVKlsqCgIAsKCvrbb1t9Env27LE9e/ZYo0aNHrvz3qxZMwsEAjZz5szweNgAhPA+rs3MQkJCLEIE71P5zJkzLWLEiNaoUaNHvxYcHGwffPCBrVu3zv744w8zM7t27ZotXbrUateubbFjx370sXXr1rWYMWPajBkznvqxAv/LnsXx/3deeeUVM7PH/vWe4x94/p7VOeDevXvWqlUra9WqlaVJk+ZvP2bmzJmWOHFie+eddx79WsKECa1atWo2d+5cCwsLMzPeLwDP0vM6B1y6dMn27NljlSpVsihRojz69ezZs1umTJnsu+++e/Rra9euNTOz6tWrP/Z7VK9e3e7cuWNz5879jx4r/rm//55JPHfvvPOOHThwwL799lsbMGCAJUiQwMz+9eJ69epVu3fvnufvERwcbDFjxjQzs61bt5qZWe7cuR/7mJdfftmSJ0/+qAN4dsL7uP4ntm7daunTp3/sTbiZWd68ec3sX/8zuJCQENu5c6fdv3//L+eKKFGiWI4cOThXAE/pWR3/9+/ftytXrtjdu3dt165d1rlzZ4sVK9ajY9uM4x/wg2d1Dhg4cKBdvnzZOnfubLNnz/7b3datWy1nzpx/+Qe+vHnz2ujRo+3AgQOWLVs23i8Az9DzOgf8eUM+WrRof2nRo0e33bt325kzZyxJkiQWFhZmESNGfOzG3p8fZ2b222+/WcOGDZ/sL4xwwQ07n3r11VctZ86c9u2331rFihUf/Yu5mVnRokVt9erVnr9HvXr1bOLEiWZmdvr0aTMzS5o06V8+LmnSpHbq1KlwedwA3ML7uP4nTp8+7Tz+zezROcDrXPHnv7wB+Gee1fG/efNmy5cv36P/f4YMGWzevHkWP378R7/G8Q88f8/iHHDmzBnr2bOn9evX7y835P/d6dOnrXDhwn/59X8/B2TLlo33C8Az9LzOAYkTJ7a4cePaL7/88tivX7x40fbs2WNmZidPnrQkSZJYhgwZ7MGDB7Z+/XorWLDgo4/98/X/5MmTT/rXRTjhht0L6Ouvv7bLly97ftzLL7/86P99+/ZtMzOLGjXqXz4uODjYrl27Fn4PEMA/9jTH9T9x+/Zt5/H/Z//3/9v1sX92AOHnPzn+M2fObEuXLrWbN2/ar7/+asuWLfvLT3Tl+Af87WnPAR06dLDUqVNbgwYN5C68zgG8XwCejWd5DogQIYI1btzY+vbtax07drT333/frl27Zu3bt7e7d++a2f8d+zVr1rQePXrY+++/b8OGDbN06dLZTz/9ZMOHD3/s4/Dfww27F1CuXLn+8ebPb4H981ti/92dO3f+9ltkAfz3PM1x/U9EixbNefz/2f/9/+ZcAfz3/CfHf+zYsa1EiRJmZlahQgWbNm2aVahQwbZs2WLZs2c3M45/wO+e5hywfv16mzx5si1fvtzzv2XLOQDwt2d9DujRo4dduHDBvvzyS+vTp4+ZmZUqVco++OADGzly5KP/mW2SJEls3rx5VqdOHStVqpSZ/es6Y8iQIVavXr2n+s/y4D/DDbsX0KVLlx7dDVeiRYtmceLEMbP/+9b206dPW0hIyGMfd/r06cf+WzcA/vue5rj+J5ImTfq338b+5//85c9/sfv3c8XffezTfocfALfwPP7feecdq1Onjn333XePbthx/AP+9jTngPbt21uhQoUsVapUj/6j9RcuXDCzfx2vx48ftxQpUpjZv45t13Ft9vfnAN4vAP89z/ocECVKFBs7dqz16tXLDhw4YIkTJ7b06dNbzZo1LUKECJY2bdpHf0bhwoXt999/t507d9rNmzcte/bsj/7n8OnTpw/PvzaeADfsfCwoKOhvf/2dd975x/8b9xw5cpjZv/5bN//+Ynvq1Ck7ceLEYz85DsCzE57H9T+RI0cOW7lypV27du2x/8bFhg0bHnUzs6xZs1qkSJFs8+bNVq1atUcfd/fuXdu2bdtjvwbgn/lvHP9hYWH28OFDu3r16qNf4/gH/CE8zwHHjx+3Y8eOWapUqf7yceXLl7c4ceI8+mnROXLksLVr19rDhw8f+06cDRs2WPTo0R+9Cef9AvBsPa9zwJ8SJ05siRMnNjOzBw8e2KpVqyw0NPQv3zkXMWLER+cDM7Nly5aZmT36jn7893DDzsdixIhhZvaXA+1p/jfuWbJksYwZM9ro0aOtcePGFjFiRDMzGzFihAUFBVmVKlXC74EDcArP4/qfqFKlivXr189Gjx5tbdu2NbN/vbGfMGGChYaGPvqX9Dhx4liJEiVsypQp1qVLF4sVK5aZmU2ePNlu3LhhVatWfao/H0D4Hv9XrlyxGDFiWOTIkR/7mLFjx5rZ4z/lkeMf8IfwPAeMHj3abt269VhfsWKFDRkyxPr162cZM2Z89OtVqlSxmTNn2uzZsx9d81+4cMG+//57K1eu3KP/Zh3vF4Bn63mdA/5Ov3797PTp0zZkyBD5cefPn7e+ffvaq6++yg275yAoEAgEnveDwN/btGmT5c2b18qUKWPVq1e3yJEjW7ly5R4d6P/UggULrHz58lasWDGrXr267dq1y4YOHWoffPCBjR49OpwfPYC/E97H9Zo1a2zNmjVmZjZkyBCLHj26ffDBB2b2r29p//efCletWjX74YcfrHXr1pY2bVqbNGmSbdy40ZYvX/7Yx23ZssXy589vmTNntkaNGtmJEyfs66+/tsKFC9uSJUv+g7898L8tPI//OXPmWMuWLa1KlSqWLl06u3v3rq1du9Zmz55tuXLlsl9++cWiRIny6OM5/oHnL7yvAf7/TZw40erXr2+bNm167Kb9gwcPrGDBgrZr1y5r166dJUiQwIYPH27Hjx+3TZs2WYYMGR59LO8XgGfneZ0DpkyZYrNmzbLChQtbzJgxbdmyZTZjxgxr0KCBjRkz5rHfo0iRIpYvXz5LmzatnTlzxkaPHm03btyw1atXW7Zs2cLlceIfCMDXevbsGUiWLFkgQoQIATMLHDly5D/6/X744YdAjhw5AlGjRg0kT5480Llz58Ddu3fD58ECeCLheVx37do1YGZ/+3+6du362Mfevn070LZt20CSJEkCUaNGDeTJkyfw448//u3vu3bt2kD+/PkDwcHBgYQJEwaaN28euHbt2lM/TgD/El7H/6FDhwJ169YNpE6dOhAtWrRAcHBwIEuWLIGuXbsGbty48ZeP5/gH/CG8r+3/3YQJEwJmFti0adNf2qVLlwIffPBB4KWXXgpEjx49UKRIkb/9uECA9wvAs/Q8zgEbNmwIFC5cOBAvXrxAcHBwIHv27IGRI0cGHj58+Jffo3Xr1oHUqVMHokaNGkiYMGGgZs2agcOHD4fbY8Q/w3fYAQAAAAAAAD6if/4vAAAAAAAAgP8qbtgBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Ag37AAAAAAAAAAf4YYdAAAAAAAA4CPcsAMAAAAAAAB8JNKTfmBQUNCzfBzA/6RAIPC8H8ITq1evnux169Z1tmLFislttGjRZI8ePbqzpUyZUm6rVKnibA0bNpTbrFmzyr57925nK1y4sNyOGTNG9jp16jhbwYIF5bZ9+/ayN23a1NkqVaokt5MnT5b94cOHzjZw4EC5PXfunLMlSJBAblevXi172bJlna1t27ZyO3jwYNmbNGnibD179pTb0qVLy+4XXs+5okWLOtv48ePl9s6dO7Kr8+TRo0flNnPmzM42aNAguVXPGTOzdevWOVu/fv3ktnbt2rJ36tTJ2S5evCi3WbJkkT1evHjO1qZNG7ndtWuX7CdOnHC2/fv3y+3atWudzet8mSNHDtmLFy/ubLVq1ZLb69evy3748GFnmzp1qtyqr4XfhISEyJ4zZ05nq1q1qtzmy5dP9rhx4zqb12ttunTpnO2XX36R29DQUNlbtmzpbEWKFJHbcePGyX727Fln8zqn7tixQ/arV686m9fjjh8/vuyvvPKKs3Xu3Flut2/f7mwrVqyQ2w8++ED2lStXOluuXLnkdtq0abKnSZPG2a5duya3Q4cOld0vvI7RpUuXOlu2bNnkdsuWLbKvWbPG2bxex0uUKOFsH330kdzGiBFDdvXa4PV19Tq3ZM+e3dm8rkk//vhj2Y8dO+ZsN27ckNs9e/bInjhxYmfz+nwnT57c2fLnzy+358+fl129h8idO/d/9HuHhYU528SJE+V269atsv+J77ADAAAAAAAAfIQbdgAAAAAAAICPcMMOAAAAAAAA8BFu2AEAAAAAAAA+wg07AAAAAAAAwEe4YQcAAAAAAAD4CDfsAAAAAAAAAB+J9LwfAIAXQ7t27WSfNm2as6VJk0ZuixcvLnuECO5/W9i9e7fcTp482dm++OILuc2cObPs9+/fd7axY8fKbfPmzWXftGmTs9WvX19u9+/fL/vHH3/sbK+88orcrlq1SvZ9+/Y5W/v27eV25MiRzvbGG2/I7e+//y57lSpVnK1Xr15y+9FHH8k+ZswYZ1u/fr3cvijmzp0r+6uvvupsGTNm/I/+bPWcCwkJkdv58+c7W5EiReQ2T548sn///ffOdvXqVbmNFSuW7IkSJXK2w4cPy23dunVlX7RokbOVLl1absuVKyd7/Pjxna1atWpyW7RoUWdr06aN3A4bNkx2dW5RrxFmZj169JB98+bNznbgwAG5DQ0Nld1PXnvtNdnjxYvnbDlz5pTbTJkyya6+vo0aNZLb999/39kWLlwot3PmzJE9Xbp0zpY8eXK5vXXrluzq3NavXz+5rVixouyLFy92tk8//VRuvV7HBw0a5GzqusZMf04KFiwot0ePHpV96tSpznb+/Hm5VdegZvpaslOnTnL7ovC6lilZsqSzqWtOM+/jcOjQoc7WtWtXuX3nnXeczevrWqlSJdnVa0Pq1KnlNkGCBLKr89qoUaPk1uvvpT4nPXv2lNvp06fL/t133zmb1zVA+vTpnc3r+Pf6Wr355pvOVqBAAbmdOHGi7FWrVnW2KVOmyO2T4jvsAAAAAAAAAB/hhh0AAAAAAADgI9ywAwAAAAAAAHyEG3YAAAAAAACAj3DDDgAAAAAAAPARbtgBAAAAAAAAPhLpeT8AAC8G9SPbzcxWrlzpbHHjxpXbZs2ayb5ixQpnGzJkiNxu3rzZ2Ro3biy3Xj/GvkiRIs6mfrS5mVmhQoVkr1OnjrNNnTpVbjt16iS7+nHxy5cvl9soUaLIfvDgQWcbOXKk3K5atcrZ7t27J7fvvvuu7MePH3e2jh07ym3fvn1lVz/SPXbs2HLbpEkT2f2ibdu2sm/ZssXZwsLC5LZ58+ay375929kiRND/7qi+thUqVJDbWLFiyT579mxnK1++vNz26tVL9t69eztbpUqV5DZ69Oiynzt3ztlefvlluU2SJInsadKkcbYRI0bIrTqfTpw4UW779Okju6Ies5nZrl27ZF+8eLGzZc2aVW5DQ0Nl95No0aLJnjNnTmcbPny43AYCAdnfeOMNZ4sZM6bcFixY0NkmT54st927d5d9/vz5ztalSxe5rVatmuzqOB0/frzcel3bJE+e3Nly5Mght99++63s6tyVN2/ep35cXq+VXufU1q1bO1uePHnkNmrUqLI3bNjQ2WrWrCm3n3/+uex+Ubx4cdlTpEjhbJ999pncqtdSM7OffvrJ2U6fPi236dOndzb13sLMbN26dbIXKFDA2fr16ye3V65ckb1r167Oli1bNrl98OCB7Oo9V+TIkeX2+vXrsqvP99ixY+VWHf8JEiSQ25CQENk//fRTZ+vRo4fc7t27V3Z1nX///n25fVJ8hx0AAAAAAADgI9ywAwAAAAAAAHyEG3YAAAAAAACAj3DDDgAAAAAAAPARbtgBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Eik5/0AALwYwsLCZO/SpYuzLVu2TG4rVKgge6JEiZwtWbJkcjt8+HBny5Ahg9zOmjVL9urVqztb3bp15TZu3LiyDxgwwNm2bNkit0uWLJF93Lhxzub1+UyePLnstWrVcraDBw/K7YwZM5xt1KhRctuuXTvZU6ZM6Wwvv/yy3BYrVkx29fVImjSp3L4o8ubNK3uCBAmc7cqVK3LbuHFj2efOnetsTZo0kdv33nvP2W7duiW3bdu2lT1z5szONn36dLn97bffZO/Xr5+zffbZZ3IbMWJE2b/99ltnW7FihdwOGjRI9ty5czub17HQsmVLZytSpIjcZsqUSfbVq1c726uvviq3hw4dkv2PP/5wtp49e8rti6Rbt26yq/P70aNH5dbrtXbVqlXONnXqVLlNkiSJs0WIoL9vIWbMmLJfuHDB2bZv3y63Xp+T9OnTO9uJEyfkdt++fbJv2LDB2bwe9wcffCD7sWPHnO3UqVNyq17nu3btKrfHjx+X/ezZs84WO3Zsud25c6fsMWLEcLbLly/L7YsiS5Yssh8+fNjZcuTIIbffffed7JcuXXK2+vXry606RtXXzcxsz549sk+aNMnZfv31V7n1unZp0KCBs92+fVtuva5Z1d/7888/l9umTZvKfvr0aWcbOXKk3GbLls3ZihcvLrelSpWSfeDAgc524MABufV6/q5du9bZsmfPLrdPiu+wAwAAAAAAAHyEG3YAAAAAAACAj3DDDgAAAAAAAPARbtgBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Ag37AAAAAAAAAAfCQoEAoEn+sCgoGf9WICn1qBBA9kjRYrkbCNHjgzvh/PEnvDw84W33npL9jlz5jjbiBEj5HbZsmWyJ02a1Nm8PoflypVztjJlysjtkiVLZO/bt6+zffnll3L7008/yb5u3Tpnq169utx27txZ9vPnzzvb9OnT5Xbr1q1P3S9fviy3n332mbONHj1abkNCQmR/4403nO2TTz6R2zp16sieN29eZytUqJDcqnOTnxQoUED2Dh06OJvXOfbs2bOynzt3ztlmz54tt6tWrXK2xYsXy+3p06dl37dvn7NNmzZNbps0aSL7hg0bnK1Zs2ZyO3PmTNmjRInibLFixZLbY8eOya6O02HDhsnt7t27na1s2bJymydPHtnVuaVly5ZymyhRItlPnTrlbEWKFJHbNm3ayO4n6nXYzGzPnj3Olj9/frnt0qXLU//Z77//vtwePHjQ2VKlSiW3rVq1kv3GjRvO5nWMf/3117KXLFnS2bzOTQ0bNpR96dKlzhYhgv5eDvV1NjOrWrWqs3m9l4wdO7az/Sd/JzOzGjVqOFu0aNHk9uTJk7JHjx7d2S5cuCC3Xq8VfnHnzh3Za9as6WyrV6+WW3UONTM7evSosxUuXFhuW7Ro4Wxez8fGjRvLnilTJmc7ceKE3BYrVkz2Tp06OdvYsWPlNkGCBLLXq1fP2dKnTy+3devWlf2rr75ytlu3bsltcHCws3kdR+o60czs4cOHzrZmzRq59TrnqWsIr+PG6/P5J77DDgAAAAAAAPARbtgBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Ag37AAAAAAAAAAf4YYdAAAAAAAA4CNBgUAg8EQf6PGjj4FnKWrUqLKvWLFC9tDQUGeLFCnSUz2m8PCEh58vqB+3bWa2c+dOZ8uWLZvcxokTR/YlS5Y4W5IkSeT27bffdrabN2/K7apVq2SPHz++s3Xv3l1uvX4s+yuvvOJsiRMnlttTp07JvnjxYmfz+lH0iRIlkv2DDz5wNq/XkXfffdfZ3njjDbnNnDmz7D179nS2ESNGyG2XLl1kX7t2rbPt379fbr2eY36xZcsW2dXXrnbt2nLbsWNH2Rs1auRsK1eulNt9+/Y5W9WqVeX2/Pnzsrdu3drZvI7BsLAw2SdNmuRsS5culdsOHTrIXrx4cWfzOiemT59ednW+nT9/vtxOnDjR2aZOnSq37733nuy5cuVyNq+/88KFC2V/6623nK1mzZpymzZtWtn9ZNeuXbJHjBjR2dRrpZnZvXv3ZN+7d6+zeZ1frly54myff/653BYuXFh2dQ336quvyq3Xnz1u3Dhny58/v9wOGTJE9p9//tnZmjVrJrezZ8+WvXLlys42d+5cuVXXF17nj/fff192db72un5o2LCh7C1btnS2ihUryq36fPnJ7du3ZY8cObKzFS1aVG6jRIkie9OmTZ1tzJgxcluoUCHZFa/ri82bNzvb4cOH5TZDhgyyHz9+3Nm83vecOXNG9l9++cXZvK5NvK4B9uzZ42xen5ONGzc62++//y636vlnZnb06FFne/jwodyWLl1advX38nq/5nU+/RPfYQcAAAAAAAD4CDfsAAAAAAAAAB/hhh0AAAAAAADgI9ywAwAAAAAAAHyEG3YAAAAAAACAj3DDDgAAAAAAAPARbtgBAAAAAAAAPhLpeT8A4El07NhR9tDQUNmHDx8eng/nf9LevXtlP3v2rLOFhYXJ7c6dO2V/8OCBszVs2FBuN23a5Gxly5aV26hRo8p+8uRJZ/vtt9/kNl26dLLHiBHD2dTfyczs7t27spcoUcLZUqRIIbe1atWS/aeffnK2kiVLym3MmDGdLXXq1HI7ePBg2fPly+dsgwYNktslS5bIfvToUWfLnj273L4oJkyYIPuXX37pbPXq1ZNb9ZwxM7t27ZqzTZ48WW67du3qbEOGDJFb9XcyM7t//76z1axZU24vX74se8SIEZ3N6/n6ww8/yH7jxg1ne+mll+R27dq1shcoUMDZPv30U7lVX+cxY8bIbZMmTWR/+PChs4WEhMit159dvnx5Z0ubNq3cvkiKFCki+4IFC5xNPS/MzKpVqyZ7kiRJnO3zzz+X26xZszrb+PHj5dbr2kRdFyVOnFhuu3fvLnv79u2d7fvvv5fbWLFiyd6vXz9nS5kypdx6PQ/UuW3s2LFyq15nChUqJLdegoODnc3rNShXrlyyq+eg1/m6cuXKsvuFei010+fBbdu2ye2ZM2dkv3nzprN5PS/UcfThhx/K7bBhw2T/5ptvnK1Hjx5yu2vXLtnVuWXNmjVyW6NGDdkvXLjgbF7vTWrXri27Ov5Pnz4tt5UqVXI2r7+T132ChQsXOlvv3r3l9rXXXpP93r17zub1vudJ8R12AAAAAAAAgI9www4AAAAAAADwEW7YAQAAAAAAAD7CDTsAAAAAAADAR7hhBwAAAAAAAPgIN+wAAAAAAAAAH4n0vB8A/rmXX375P9qfOnUqnB7Jf0+TJk1kv3LliuzqR9jjyagf1W2mf+x96dKl5TZTpkyyHzt2zNm8fgR50qRJnc3rWIgWLZrslStXdrYHDx7Ibb169WR/++23nS158uRye/PmTdnVj7Jv27at3KZPn172ESNGONvnn38utw0aNHC227dvy23ChAllT5MmjbNt375dbqNGjSp7jhw5nO3o0aNy+6KoWrWq7KlTp3a2Zs2aye3Vq1dlX7VqlbNlzZpVbt966y1n27Bhg9xWqlRJ9hUrVjjbtWvX5Fadl8z0MR4vXjy5rV27tuzx48d3tpIlS8rt6tWrZX/33Xedbfjw4XK7fv16Z/M6X164cEH21q1bO9uoUaPk9vDhw7KnSJHC2cqXLy+3I0eOlN1Ppk2bJvuYMWOcrUePHnJbrlw52dU13Jo1a+T2q6++crZt27bJbY0aNWT/9ttvnc3r7zR9+nTZ1ev0+++/L7cnTpyQPV++fM7mdX2hzh9m+npu0qRJcqtea72u89VxaGY2btw4Z+vZs6fcNm7cWPZkyZI5W4cOHeT2RaFe78z0e9OQkBC5vX79uuznzp1ztgIFCshtzJgxZVdKlSol+8KFC51NnQ/NzFKlSiV74cKFnc3r+Th37lzZ1fsmr/OS1/Xa4MGDnW3//v1y27dvX2dTr+FmZsWLF5ddndcGDBggt17PMXWuv3Pnjtw+Kb7DDgAAAAAAAPARbtgBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Ag37AAAAAAAAAAf4YYdAAAAAAAA4CPcsAMAAAAAAAB8JNLzfgD45ypUqCB7jRo1ZC9cuHB4Ppxw07ZtW2eLFy+e3LZo0UL248ePP9Vjwv+pU6eO7EmTJnW2pUuXym2ECPrfDrp37+5sHTp0kNvBgwc7m9fzInr06LK/9tprzqYes5lZ8uTJZb9x44az9erVS269PifNmjVztpQpU8ptjBgxZI8aNaqzvffee3J7+/ZtZztz5ozc5s6dW/atW7c62/jx4+XW67m/YsUKZ2vcuLHcviju3r0re7du3ZxtyJAhcut1HBYoUMDZXnrpJbmdOHGis3kd31myZJG9YMGCzvbuu+/K7fbt22UvWrSos2XMmFFur127Jnu7du2c7fXXX5fbihUryp4+fXpnO3funNyqa5ckSZLIbZkyZWSvX7++s12+fFluK1euLHvfvn2dLU+ePHL7ImnZsqXsGTJkcLZx48bJ7Ycffih7sWLFnvr3TpMmjbOpc4uZWXBwsOyfffaZs7Vu3VpuI0eOLLs6Hu7cuSO3Xtf5bdq0cbaOHTvKrVdXrxWLFy+WW3Vtc+zYMbktW7as7A0bNnS2/v37y60615uZhYSEOJvXa+eLIiwsTHb1Ot+5c2e59Xq+Tpo0ydm8Pr+9e/d2tlOnTsmt19ddXWsHAgG5/fXXX2VXn5ObN2/K7e7du2VXx3CRIkXkdtWqVbLnypXL2bw+nxMmTHC2ZcuWyW3NmjVlnz59urN5XT94vQ7Mnz/f2d544w25fVJ8hx0AAAAAAADgI9ywAwAAAAAAAHyEG3YAAAAAAACAj3DDDgAAAAAAAPARbtgBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+EhQIBAIPNEHBgU968eCf5M3b15nW7RokdyePn1a9mzZsj3VY/pPFSxYUPbVq1c72/79++U2c+bMT/WYnrcnPPx8oVixYrLPnDnT2cLCwuQ2adKksp84ccLZOnToILevvfaas3344Yf/0ePau3evs7311lty62X27NnOduXKFbldsmSJ7IcPH3a2FClSyO2BAwdkV1/r7t27y22yZMmcbdWqVXLbu3dv2desWeNs2bNnl9s6derI3r9/f2cbO3as3FasWFF2v1DHkZlZkyZNnK1BgwZyu2DBAtl/+OEHZ2vatKncpkqVytk2bNggt3fu3JE9fvz4zhYzZky5rV27tuyXL192tkaNGsnt8OHDZVfntfbt28vtN998I7t63Dt27JDb5cuXO1vJkiXldufOnbK/9NJLzlazZk257dOnj+xly5Z1NnVcmHmfE/2kUqVKsqtz8PXr1+XW6xx79+5dZ/vggw/k9syZM87mdV6LFSuW7BEiuL/vQb3mmJmlTp1a9qlTpzrbhAkT5NbrOduvXz9nu3nzptyq856Z2ZEjR5zt5MmTcvvqq686m9cxrt5DmJkNGDDA2apVqya3XueuaNGiOZu6rjEzmzNnjux+oV5LzfSxNH/+fLmNHj267Lly5XK2gQMHyu3ChQud7datW3Lr9XtHjBjR2RYvXiy3XtfpXbp0cbauXbvKbZEiRWRXz9f169fLrZcqVao4W6ZMmeS2RYsWznbo0CG5Vc8RM7M9e/Y4m9e14EcffSR7njx5nG3WrFly+9VXX8n+J77DDgAAAAAAAPARbtgBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Ag37AAAAAAAAAAf4YYdAAAAAAAA4CNBgUAg8EQfGBT0rB/L/5SoUaPKvmLFCmcLDQ2V24YNG8ru9ePgnxWvH3FdsmRJZ8uZM6fcev3Idb96wsPPF2rUqCG7+jHiN2/elNspU6bIXqBAAWebPXu23J45c8bZvH4MuNePIE+bNq2z3b9/X25PnTole9OmTZ1txowZcnv16lXZd+/eLbvide6aOHGis509e1ZuY8SI4WwlSpSQ21WrVj11r127ttyuXbtW9o4dOzqb+juZma1evVp2v4gTJ47sd+7ccbaIESPK7cOHD2UPDg52tt69e8uter176aWX5Hbbtm1P/bhSp04ttx9//LHsyvnz52V/++23ZVfnNa/XUq+v5aVLl5wtZsyYcquOwy+++EJuO3ToIHubNm2c7ciRI3LbqlUr2Xv27Ols/fr1k9vr16/L7ifTpk2TPVmyZM4WP358ufV6zerfv7+zbd++XW7V6/TGjRvl1ut4mDVrlrO9/PLLcut13uvevbuzJU2aVG579Ogh+4YNG5zN62sxdepU2du2betsV65ckdsWLVo4m9d1i9f5ZcyYMc7mda73+jur3rhxY7mNGzeu7H6RPXt22cuUKfPUW6/j7PPPP3c2r+v49u3bO5vXtZ3X9VmvXr2cbdCgQXLrde5R+2XLlsntokWLZFd/r5UrV8rtiRMnZI8SJYqzrVu3Tm7Tp0/vbNWqVZNb9XU20+/JvM4dP/zwg+wLFixwtnnz5smtV/8T32EHAAAAAAAA+Ag37AAAAAAAAAAf4YYdAAAAAAAA4CPcsAMAAAAAAAB8hBt2AAAAAAAAgI9www4AAAAAAADwEW7YAQAAAAAAAD4S6Xk/gP9VU6ZMkT00NNTZmjdvLrcTJkx4qscUHurXr+9spUqVktvp06c7286dO5/6MSF8XLx4UfZBgwY52zfffCO3bdu2lf3evXvOlitXLrkdM2aM7EqPHj1kr1OnjrONHj1abhcsWCD7Tz/95GzJkiWT23LlysmeOXNmZ7ty5Yrcrl27VvYvv/zS2T788EO5XbJkibMVLFhQbrdu3Sr7zJkznS116tRyO2rUKNkDgYCzrVy5Um5fFA8fPpS9TZs2T/17t27dWvaePXs627Jly+Q2d+7czrZu3Tq5DQ4Olv2jjz5ytlu3bsltmTJlZP/444+dbffu3XKrjiMzs2HDhjlb0qRJ5fbnn3+WvUaNGs6WL18+uY0YMaKzDR06VG7r1asn+44dO5ytSZMmcpszZ07Z1ddy+fLlcvsiuXr1quwHDx50tnTp0sntvHnzZG/ZsqWzHT58WG7v37/vbFOnTpVb9bphZnbhwgVn69Wrl9x6XQN8++23zrZ//365ffDggew//PCDs5UvX15u8+TJI/tvv/3mbF7na3Wsvfnmm3IbEhIiuzoWt2zZIrfbtm2TXZ1D9u3bJ7fq/Z6fbN++Xfbz5887W9y4ceU2duzYsu/Zs8fZfvzxR7n97rvvnC1y5Mhyu2nTJtmbNm3qbLVr15bbDRs2yK6uPwYPHiy3FSpUkP3u3bvOdujQIbn1ki1bNmfzeh04cOCAsx07dkxuvd4LXr9+3dlOnTolt17XPer56fX+4UnxHXYAAAAAAACAj3DDDgAAAAAAAPARbtgBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Ag37AAAAAAAAAAf4YYdAAAAAAAA4CORnvcD+H9VlSpVZC9btqzsS5cudbZp06Y91WMKD3HixJG9Ro0aznbr1i257dOnj7MFAgH9wPDMderUSfbEiRM7W6FCheQ2JCRE9nHjxjnbggUL5DZq1KjOli1bNrkdP3687ClTpnS20NBQuZ04caLse/bscbaMGTPKbfny5WUvV66cs82fP19ud+3aJXvhwoWdLXPmzHKrzntdu3aV2wgR9L8/LVy40NnU58PM7NSpU7IvWbLE2byen15fK78oXbq07CNHjnS2okWLyu3Zs2dlL1OmjLP9/vvvclu7dm1nO3DggNxOmTJF9r59+z7Vn2tmVqRIEdkTJkzobKdPn5bb1KlTy54+fXpnS5QokdyuXbtW9l9//dXZli9fLrfqfNuhQwe5jRw5suyTJ092Nq/z0jfffCP79evXn6q9aNT52Uxfp0WLFk1uBw0aJHu9evWcLVasWHKbLFkyZwsODpbbuXPnyq6Olx9++OGpH5eZWb9+/Zzt9ddfl9vGjRvLrs4hXl8Lr2sE9bXetGmT3CZIkMDZrl279h89rtmzZztbqVKl5LZZs2ay16xZ09m8rp1flHPE9OnTZVfv8fLkySO36jXJzKxgwYLOVqFCBblNly6ds82ZM0duK1asKPurr77qbIcOHZLbjh07yq4+J7lz55bbZcuWya7eqz98+FBuN27cKPvNmzedrUWLFnKrXmsbNWokt15fy4YNGzrbokWL5NbrPcC5c+ec7aOPPpJbr+PqT3yHHQAAAAAAAOAj3LADAAAAAAAAfIQbdgAAAAAAAICPcMMOAAAAAAAA8BFu2AEAAAAAAAA+wg07AAAAAAAAwEciPe8H8CJTP+55/PjxcvvgwQPZ1Y97fp4/Arxv376yv/HGG872/fffy+2OHTue6jHhv6Nr166yR48e3dnixIkjtytXrpR93LhxzvbTTz/JbYwYMZxt7ty5cuv14+KbNGnibMeOHZNbr+Ph888/dzavYyVbtmyynzlzxtl69uwpt7NmzZJ91KhRzub1483Vea9x48Zy6/W1On/+vLP98ccfcrtu3TrZ79+/72xffPGF3JYvX152v8iePbvsixYtcrb9+/fL7XvvvSe7OsYLFiwotz/88IOz9e/fX25/+eUX2W/cuOFsgUBAbhs2bCh727Ztnc3r3JIzZ07Z1XmrV69ecpsxY0bZ1XF29+5duVXH0ciRI+W2W7dusl+5csXZRowYIbfp06eX/cKFC862Z88euX2RqK+PmVm0aNGcbd++fXJ79uxZ2RcvXuxs33zzjdxu2LDB2dasWSO3Xq8r6rmRNGlSue3du7fslSpVcjb1fDbzPqcOHjzY2Xbu3Cm3Xq+H5cqVczZ1fWBm1qhRI2dT5y0z7/Ne6dKlna1ly5Zyq15HzMwyZcrkbFGiRJHbF0W/fv1kT5gwobN5nb9bt24tu3q/HRoa+tSPK1asWHL7ySefyK5e09q0aSO3b7/9tuyxY8d2Nq9jweseg/q9vd4DqNc7M/1+7dSpU3K7bNkyZ1u/fr3cej0/q1ev7mxez78333xT9gwZMjib13n+SfEddgAAAAAAAICPcMMOAAAAAAAA8BFu2AEAAAAAAAA+wg07AAAAAAAAwEe4YQcAAAAAAAD4CDfsAAAAAAAAAB/hhh0AAAAAAADgI0GBQCDwRB8YFPSsH4vvpEmTRvaDBw86m9en9aOPPpJ9yJAhsj8rKVKkkH3ZsmWynzx50tmKFSv2VI/p/2VPePj5Qr169WQfPHiws1WqVElu9+/fL/v06dOdLWXKlHKbPn16Z/vyyy/l9uOPP5Y9ZsyYzhY7dmy5bdeunezqWJoyZYrcBgcHyx4WFuZsESNGlNsxY8bIXrx4cWfzeh1p2LChs1WvXl1uu3XrJvu8efOcbePGjXIbN25c2VOnTu1sNWrUkFuvc6pfDBw4UPZ169Y5W6xYseR23LhxspctW9bZQkJC5PbChQvOdu3aNbm9d++e7Op5MXToULlt0qSJ7NevX3e2ggULyu27774re/To0Z3N6xpg6dKlsh89etTZVqxYIbdz5sxxtqxZs8rtlStXZG/evLnsyo0bN2TPkCGDsyVJkkRuX6TronTp0smujocff/xRbr1ex7t27epsf/zxh9yeOHFCdqVu3bqyq+ueixcvym2ZMmVkHzRokLN1795dbnft2iX75cuXnS1v3rxy+/XXX8s+depUZ/O6Npk4caKzDRgwQG7V38lMvxZnzJhRbr2uEQoUKOBsixcvltvTp0/L7hde12Dbt293tvLly8tt7dq1ZVfXF6tWrZLbLVu2ONu3334rtwkTJpS9U6dOzvbTTz/JrddzTj2fvd4D5MyZU/bChQs7m9c1gNffSx0LXvdVatas6WyfffaZ3KrrGjP9tc6cObPcNm3aVPZLly45m7pXZGY2adIk2f/Ed9gBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Ag37AAAAAAAAAAf4YYdAAAAAAAA4CPcsAMAAAAAAAB8hBt2AAAAAAAAgI9Eet4P4HmqUqWK7OPHj5c9EAg429ixY+V2xIgRsj8vc+bMkT1WrFiyt2vXLhwfDfwkXrx4svfu3dvZ1q1bJ7eTJ0+Wffny5c7Wvn17ua1cubKzbdmyRW7feecd2atVq+ZsiRMnltvs2bPLHjduXGfzOn8EBwfLnjp1amcbNmyY3N69e1f2e/fuOdvRo0fltlSpUs6WIkUKub1y5Yrs+fPnd7bPPvtMbj/55BPZa9as6Wx79uyR2xfF5s2bZW/QoIGzbdu2TW5r1aole4ECBZytZ8+ecqte59966y253bFjx1P/3pEjR5bbhw8fyp4wYUJnO3z4sNwmTZpU9ixZsjjbhg0b5DZjxoyyq+fJ6tWr5Xbx4sXO5nU9tnv3btmrV6/ubH369JHbL774QnZ1brlz547cHjx4UHY/SZIkiewFCxZ0ts6dO8utV+/QoYOzqWPFzOzcuXPOljt3brlNnz697EOHDnW2nTt3ym2GDBlkV3+vV155RW4nTpwou7pW//DDD+X2/Pnzsr/77rvO1qNHD7mtUKGCs3ldR/7444+yX7hwwdm8zplex+nAgQOd7fLly3L7onjttddknzZtmrMlSJBAbrdu3Sp7nTp1nC1SJH0ro2jRos42evRouR0zZozs6nV81qxZcrtx40bZixcv7mzfffed3KprUjOztWvXOpvXuUO9NzEzy5Qpk7N5Xac3bdrU2by+FidPnpQ9YsSIzub1viZRokSylyhRwtm8XmMmTZok+5/4DjsAAAAAAADAR7hhBwAAAAAAAPgIN+wAAAAAAAAAH+GGHQAAAAAAAOAj3LADAAAAAAAAfIQbdgAAAAAAAICP6J+F/AKIEyeO7K1bt3a29u3by22UKFGe6jGZef/4a68fIX727Fln8/rxw15y5crlbGnTppXb1atXy7558+anekzwv++//172JEmSOFvz5s3l1us5HS9ePGfLli2b3Pbv39/ZatWqJbclS5aUPTQ01NmmTJkit9OmTZP91q1bzvbFF1/I7dy5c2W/ePGisxUtWlRuO3bsKPvQoUOdzevHrrdp08bZ1NfRzGzw4MGyz58/39mWLl0qt16P+/Lly872xhtvyO2LIkIE/e97PXr0cDav56vampl9/fXXznbnzh25/eWXX5zt3r17cvvw4UPZe/bs6Wy//vqr3Hbp0kX2VKlSOZu6rjEza9eunex16tRxtrFjx8qt15+telBQkNweOXLE2bp16ya3X375pezRokVztty5c8ut13XPvn37nK1mzZpy+yJp2LCh7Op1Xh0rZvo1yczs/PnzzpY5c2a5rVChgrN5nXu8ruXV805da5uZZcyYUfYTJ044W3BwsNz27dtXdvV6WKxYMbmNHj267OoaYtmyZXI7Y8YMZytevLjcnjp1SnZ1Dhk5cqTcqnOTmdmGDRucLVGiRHL7oogYMaLsq1atcjav99v379+XXT2nvM4defPmdTav42Tnzp2ynz592tnGjx8vtzNnzpRdPW/ix48vt5cuXZL9zJkzzpY9e3a5XbduneyzZ892Nq9rrgsXLjhb06ZN5XbgwIGyq/dc69evl9uoUaPKPnXqVGdr0aKF3D4pvsMOAAAAAAAA8BFu2AEAAAAAAAA+wg07AAAAAAAAwEe4YQcAAAAAAAD4CDfsAAAAAAAAAB/hhh0AAAAAAADgI9ywAwAAAAAAAHwkKBAIBJ7oA4OCnvVjcfrss8+crVmzZnKbIEGCp/5zT506JfuhQ4ecLXv27HIbJ04c2detW+dsbdq0kVuvx71582Zn8/p8Va9eXfaZM2fKjsc94eHnC507d5Z96tSpzta3b1+59ep79+51tgEDBshtw4YNne3kyZNyGy9ePNmjR4/ubF5f21mzZsm+fv16Z5swYYLcVqxYUfavv/7a2aJFiya3adKkeerf+8MPP5Tbhw8fOltoaKjczps3T/YpU6Y4W48ePeQ2UqRIstesWdPZWrRoIbcJEyaU3S/UMWhmtmPHDmdLliyZ3BYsWFB29bqSOXNmuY0VK5azvf7663K7ePFi2RcsWOBsixYtktt27drJrq57vJ5TdevWlb1UqVLOtmXLFrn1OobTpk3rbHnz5pVbdQyr6xYzs8aNG8veqVMnZ1u5cqXcZsyYUXb1GqP+XDOzyJEjy+4n586dk/3KlSvOdvHiRbn9+OOPZVfn6Bs3bsit+vp5XQPUrl1b9hIlSjhb7Nix5fbSpUuyq79Xz5495XbUqFGyN2jQwNm8/s5vvPGG7Oo9iNd10dixY52tefPmcqte483M4seP72yTJk2S2127dslesmTJp/pzzbzPL35x5MgR2bt27epsXu8f8uXLJ/vZs2edbd++fXKrXhu6dOkit6+88orsrVq1crYiRYrIbdGiRWWvVauWs3mdT69evSq7uo+QPHlyuR09erTsQ4YMcbbWrVvLrXr/0aRJE7lt2rSp7Oq1+NatW3Krjm8zs2+++cbZ1PWWmff59k98hx0AAAAAAADgI9ywAwAAAAAAAHyEG3YAAAAAAACAj3DDDgAAAAAAAPARbtgBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Eik5/0AnkTXrl2dLRAIPPXvO2HCBNk7d+4s+9mzZ50tZcqUctu8eXPZ06RJ42wLFy6U2ytXrsieIEECZ1uzZo3cLlmyRHb8v+vhw4eyZ8qUydlKlSoltyNHjpT9xo0bzhYaGiq3BQoUcLaZM2fK7dy5c2W/deuWs73++uty63X+UeeI27dvy23FihVlT5YsmbPVrl1bbtu0aSP77Nmzne2tt96SW/V3PnTokNx6nZu2b9/ubHfu3JHbvXv3yj58+HBnu3btmtwmTJhQdr/ImTOn7BUqVHC2X375RW6zZcsme5kyZZztjTfekNutW7c626hRo+T2t99+k33SpEnOVrlyZbm9f/++7FOmTHG2ePHiyW2JEiVkP3DggLPVrFlTbr2Ow/r16ztbv3795Hbo0KHO1qtXL7nt3bu37O+//76z7d69W27VtZ6Z2blz55zN63XzRVK9enXZ1Wve559/Lrdez9lPPvnE2bw+x+q5kTFjRrn96aefZE+RIoWzqXOimdn8+fNlL1KkiLN5XV/UrVtXdvVaPGPGDLkdPHiw7Oqc63VObdKkibOtXr1abr2uM7/44gtnq1KlitwePHhQ9mHDhjlbrly55NbrOegX8+bNk33ZsmXO5nXu97ru3LNnj7MVKlRIblu1auVs7dq1k9v48ePL/uOPPzqb13VN+/btZT98+LCz3b17V26XLl0qe/fu3Z3t1VdflduWLVvKni5dOmc7ffq03KrX4ixZssit1zG8c+dOZ/N6/5A7d27Z1d+5fPnycvuk+A47AAAAAAAAwEe4YQcAAAAAAAD4CDfsAAAAAAAAAB/hhh0AAAAAAADgI9ywAwAAAAAAAHyEG3YAAAAAAACAjwQFAoHAE31gUNCzfixO8eLFczavHzM/YcIEZ7tz585TP6bnqXnz5rIPHTpU9ocPHzpb4sSJ5fbChQuy4595wsPPF9SPrTYzy58/v7Op49DMLDQ0VPY//vjD2fr27Su35cqVc7ZUqVLJbZIkSWT3+tHpSo4cOWTv0aOHsz148EBu9+/fL/vw4cOdrVChQk+9NTPLkCGDs12/fl1uW7du7Wz58uWT208++UT2aNGiOZs6J5qZjR8/XvaKFSs6W9OmTeV2yJAhsvuF14+mT5QokbMtX75cbrNkySJ7iRIlnK1Lly5y+9tvvzlbnTp15LZAgQKyq/O31/PR688uWrSos3k9H0+fPi177ty5nW369Olyq86nZmavv/66s6nXCDP9GqM+H2bef+evvvrK2RYtWiS3GzZskP3q1avOVqZMGbldv3697H6SMmVK2UePHu1s2bNnl9v69evLvm/fPmfzOgdcunTJ2bxe469duya72p86dUpuz5w5I3uePHmczet4WLx4sezvvPOOs3m9Ht69e1f2PXv2OFu/fv3ktlu3bs42bdo0ufV6HkyaNMnZGjZsKLdx4sSRfdmyZc7mdf5o1aqV7H7RvXt32dX78fnz58ttsWLFZK9SpYqzqa+rmdmnn37qbJUrV5bb2rVry96+fXtnK168uNxOnTpV9hMnTjhbjRo15DZ69OiyX7582dlatmwpt+r9mJnZqFGjnM3r9TBSpEjO5nUfauPGjbIPGzbM2dKnTy+3CRIkkF3dO2nSpIncer0X/BPfYQcAAAAAAAD4CDfsAAAAAAAAAB/hhh0AAAAAAADgI9ywAwAAAAAAAHyEG3YAAAAAAACAj3DDDgAAAAAAAPARbtgBAAAAAAAAPhIUCAQCT/SBQUHP+rHgCS1ZskT2EiVKyP7HH384W7Zs2eT2+vXrsuOfecLDzxf2798vu3ruZMmSRW7btWsn++3bt52tcOHCcluuXDlny5kzp9yuW7dO9ocPHzrbp59+KreFChWSXR3nISEhcjtjxgzZO3fu7Gznz5+X29DQUNm3bNnibJUqVZLbjh07Otu7774rt16fkwgR3P8+5XVODQsLkz1x4sTONmDAALmdNm2a7H5Rv3592Y8dO+Zsd+/eldvUqVPLHjduXGdTx6CZ2ahRo5xNPWYz73NL8+bNna1GjRpyq85LZmZx4sRxttOnT8vtJ598Irs6r+XOnVtut2/fLnudOnWcbe3atXKbMmVKZ7t165bc/vLLL7KXL1/e2dS5wcxs0KBBsm/YsMHZvF43EyRIILufxI8fX3Z1PKjPkZlZxIgRn+oxmZlFiRJFdnUser23adWqlezqOe11bnrw4IHs+fPnd7aKFSvKbbx48WRv3Lixs6lzj5lZrVq1ZN+7d6+zqfOxmVnatGmdrXTp0nKrrmvMzH7++WdnO3v2rNweOHBA9o0bNzpbkiRJ5NbreeAXRYsWlf3mzZvONn/+fLn1em2IFi2as82cOVNu1evlokWL5Pabb76RXb2H83rN6tGjh+wJEyZ0tmrVqsntggULZFfP55IlS8rte++9J3uuXLmc7fjx43KrXot///13uT1y5Ijs6rV4xIgRcqvOHWb6/Vz//v3lVr3v+Xd8hx0AAAAAAADgI9ywAwAAAAAAAHyEG3YAAAAAAACAj3DDDgAAAAAAAPARbtgBAAAAAAAAPsINOwAAAAAAAMBHggLqZxL/+wd6/OhzhK8SJUo428KFC+U2UqRIsk+fPt3ZGjRoILdeP6Ya/8wTHn6+oH6suplZsWLFnG3ChAlyGyVKFNkrVarkbA8ePJBb9bhjxowpt7dv35Y9RowYzrZ582a5/f7772UPDQ11NvVj083M6tatK/tXX33lbNeuXZPbH374QfYcOXI89e+dNWtWZ5s4caLcej0PDh065GwbN26U2wIFCsg+atQoZ7t7967cev2Ye794/fXXZVef38uXL8ttoUKFZC9Xrpyzbdu2TW6rVKnibOfPn5dbr8cdFhbmbNevX5fb33//XfY1a9Y427p16+S2fPnysg8bNszZBg0aJLdez2d1blq+fLncpkuXztmyZcsmt6+88orsy5Ytc7YdO3bI7Y8//ih79erVnc3rtW327Nmy+0nRokVl79mzp7PFixdPbuPGjSv7Rx995GwJEyaUW/W137lzp9xu375d9ty5czvbnDlz5PbChQuyf/PNN8722muvye3bb78te8WKFZ3t1KlTctuoUaOn/rO9jrXMmTM7W9u2beVWXT+Y6XOT1/VY4cKFZVfXH+ra2MysWbNmsvtFnjx5ZA8JCXE2r3N/vXr1ZFfX8QMGDJDbgQMHOluiRInktnbt2rKr93AXL16U25o1a8r+zjvvOJvX653Xcy5CBPf3a6lmZjZ06FDZr1696myxY8eW2y+++MLZDhw4ILfjx4+XXV3vpUiRQm7VtZ6ZWb9+/ZxNHRdmZitWrJD9T3yHHQAAAAAAAOAj3LADAAAAAAAAfIQbdgAAAAAAAICPcMMOAAAAAAAA8BFu2AEAAAAAAAA+wg07AAAAAAAAwEe4YQcAAAAAAAD4SKTn/QDw98qUKeNsESNG/I9+b7W/f//+f/R74/9dt27dkj1VqlTOdvz4cblt27at7Nu2bXO2V199VW6nTJnibIcOHZLb6NGjy/7JJ584W4sWLeT26tWrshcoUMDZYsWKJbc///yz7BkyZHC2I0eOyK3X12rmzJnOtm7dOrmtV6+es3Xr1k1uFy1aJPucOXOc7eTJk3JbrFgx2S9evOhsgwYNktsXxZgxY2T/+uuvne2bb76R26RJk8p+5coVZ0uYMKHc/vHHH86mzg1mZlmzZpW9VatWzla7dm25vXTpkuzqOPM6FkJCQmR/8803na1nz55ymz59etlz5MjxVM3MbNasWc5Wq1YtuVVfCzOza9euOVuUKFHktn379rLHiBHD2byeny+SNWvWyL569Wpnmzt3rtzmyZNH9vjx4zub1/lFnT+2bNkit15f+8WLFztblSpV5Pazzz6TvVKlSs6mjhUzs6NHj8q+detWZ/O6puratavs58+fd7bYsWPLrXoOqddwM7MJEybIPnHiRGfzOqeq55+ZWZMmTZxt/fr1ctusWTPZ/aJQoUKyV61a1dnu3bsnt0uXLpVdvb/IlSuX3DZo0MDZXnnlFbldsmSJ7Or8HjVqVLnt3r277J06dXK2b7/9Vm4//PBD2dV5z+v4X7VqlewpUqRwNnWtbGZ2+PBhZ/N6/qlj0MzsxIkTzuZ1bXLgwAHZV6xY4Wzjx4+X2yfFd9gBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Ag37AAAAAAAAAAf4YYdAAAAAAAA4CPcsAMAAAAAAAB8hBt2AAAAAAAAgI9Eet4PAH9v+PDhzhY5cmS5vXTpkux9+/Z1trt37+oHhv9ZyZIlk33mzJnOlipVKrldvXq17HXq1HG2JUuWyG3ChAmdberUqXJbuXJl2X/99denflzXr1+Xfe/evc72/fffy+2oUaNknzFjxlM/rrFjx8o+YMAAZ+vcubPclitXztnef/99ub1165bsCxYscLZDhw7J7W+//SZ7okSJnG3WrFly+6IICgqSvVq1as723nvvye2uXbtkV+eWTp06yW2LFi2cLUqUKHL75Zdfyj5+/Hhnu3Hjhtw2aNBA9q1btzpb9OjR5Xbx4sWyZ82a1dkaNWokt17Hvzp/RIig/424ePHiznblyhW53bBhg+xNmzZ1Nq/Pl9frV/v27Z2tRIkScvsiUdelZmb169d3tjVr1sht6dKlZW/SpImzqWtaM32ce10DNGzYUHZ1vX3mzBm5LVq0qOw7d+50ttdee01uT548Kbs6B6jj0MysUKFCsqvruY8//lhu1XGaJEkSuR0zZozs6mu5cOFCuX3zzTdlv3PnjrPNmzdPbl8UGzdulL127drO5vXe8vfff5d9yJAhzub1vFBf28SJE8tt27ZtZVfnj3v37sntypUrZY8YMaKzZcmSRW6jRYsmuzqfTpkyRW7nz58ve+7cuZ0tX758cjts2DBn8zq+e/XqJfuOHTuczesaf8WKFbKr6980adLI7ZPiO+wAAAAAAAAAH+GGHQAAAAAAAOAj3LADAAAAAAAAfIQbdgAAAAAAAICPcMMOAAAAAAAA8BFu2AEAAAAAAAA+EhQIBAJP9IFBQc/6sQD/c57w8POFbt26yT537lxnK1KkiNyqH7tuZhYzZkxnO3DggNzu3r3b2WrUqCG3Xj/GPkeOHM62evVqufX6EeTqx7YPGDBAbs+ePSt7SEiIs9WpU0duv/rqK9lPnTrlbOfOnZPb6NGjO1vKlCnlNn/+/LKnS5fO2UaNGiW3ceLEkf3SpUvOpn6UvJn338svPv30U9l79OjhbOo4MTNr0qSJ7D/++KOzrVy5Um5XrVrlbOvWrZNbdQyamVWqVMnZdu3aJbf9+vWTPTg42Nm+//57uV2+fLnskydPdrZy5crJbdasWWXPkCGDs1WtWlVuU6VK5WwnT56U2+nTp8t+5swZZ/N6/ZkxY4bsa9eudbZYsWLJ7c8//yy7n6xZs0Z2dY3w4MEDud27d6/sBw8edLaJEyfK7fbt25/6z40UKZLsefLkcbZFixbJ7SuvvCL7+vXrnc3rnOl1vaauqbZu3Sq3I0aMkP3ixYvOVq9ePblt2bKls82ePVtujxw5Irt6jVLXHmZmb775puzq2qZChQpyW7x4cdn9YvHixbKr83f8+PHl1usYrlatmrONHDlSbpMlS+ZsX3zxhdy2bt1a9sOHDztbo0aN5Nbr76yOlT179sjt/fv3ZR88eLCzeV0DtGrVSvZMmTI5W8GCBeVWHSuFCxeWW6/XmNDQUGdTj9nM+1yurm1SpEght2PGjJH9T3yHHQAAAAAAAOAj3LADAAAAAAAAfIQbdgAAAAAAAICPcMMOAAAAAAAA8BFu2AEAAAAAAAA+wg07AAAAAAAAwEe4YQcAAAAAAAD4SFAgEAg80QcGBT3rxwL8z3nCw88XDh48KHv69Omd7ZdffpHbDz/8UPb48eM7240bN+Q2Q4YMzjZlyhS53bRpk+yhoaHONmTIELnt2rWr7IMHD3a2xIkTy23t2rVlT5AggbMFBwfL7ZkzZ2SvVauWs40bN05u1d9r9erVclunTh3ZFy9e7GwZM2aU23fffVf2vn37OluhQoXkdtGiRbL7RaVKlWSfNGmSs925c0dut2/fLntYWJizTZ48WW67devmbO+8847cXrp0SXZ1HI0fP15uS5QoIXuOHDmcrUGDBnL79ttvy16jRg1na9q0qdzWrVtX9uTJkztbSEiI3ObPn9/Z9uzZI7fqa2Gmz2vDhw+X26RJk8quPp9VqlSR25w5c8ruJzFjxpRdHcder9Nr166Vff78+c5269YtuX3vvfecrWHDhnIbJ04c2detW+ds5cqVk1t1zjQzix07trMdPXpUbr/++mvZ+/Tp42xp06aV2+LFi8u+Zs0aZ7t27ZrcRokSxdmOHDkitylSpJD98OHDzta/f3+5VV8LM7MVK1Y4W9myZeV2xIgRsvtFqVKlZB84cKCzzZkz56m3ZmaHDh1ytuzZs8vtrFmznK1z585yW7VqVdnV9YXX+56iRYvKnjlzZmfbunWr3Hpds967d8/Zdu/eLbder7UXLlxwtpdeeklu9+/f72wFCxaU20GDBsmuzpnqzzXTryFm+v1Jr1695Nbrfeif+A47AAAAAAAAwEe4YQcAAAAAAAD4CDfsAAAAAAAAAB/hhh0AAAAAAADgI9ywAwAAAAAAAHyEG3YAAAAAAACAj3DDDgAAAAAAAPCRoEAgEHiiDwwKetaPBfif84SHny/MmzdP9pQpUzrbwoUL5TZBggSynzt3ztn++OMPuQ0JCXG2smXLym1oaKjskSJFcra7d+/K7YEDB2Tv06ePsw0bNkxuT58+LXu+fPmcTX2uzcwiR44se1hYmLNVqFBBblu1auVsJUuWlNv+/fvLXqpUqad+XBs2bJB91KhRzjZt2jS53bp1q+x+MWPGDNk3bdrkbKlSpZLbHTt2yK6eF17HWa9evZwtY8aMcquOEzOz9OnTO9u9e/fktkaNGrLXqVPH2bzOeatWrZL9/v37zla/fn257dKli+wJEyZ0tl9//VVuV6xY4Wxe5x2v3/ull15ytgsXLshtzpw5Za9SpYqzeR3/jRo1kt1PfvrpJ9kzZMjgbIMGDZJb9Tk0M9u/f7+zrVu3Tm7VuatBgwZy+/LLL8uuXsfVucfMrGDBgrJ36tTJ2W7duiW3Z86ceequrmvMzC5fviz7kiVLnC1//vxyO3v2bGfzOg7Hjx8v+82bN50tSpQocps6dWrZ1TVZ7dq15TZt2rSy+4W6zjEzu3btmrN9/PHHcnv+/HnZjxw54mxe56Vo0aI5m9dxUqZMGdmnT5/ubF5f14kTJ8quXtM2btwot17nh8qVKztb4cKFn3prZpYnTx5nU+cGM7Ps2bM725QpU+RWXSeamW3evNnZRo8eLbfNmzeXXV1Lvv3223J7584d2f/Ed9gBAAAAAAAAPsINOwAAAAAAAMBHuGEHAAAAAAAA+Ag37AAAAAAAAAAf4YYdAAAAAAAA4CPcsAMAAAAAAAB8RP/sbgD4/+natavsgwcPdjavH5kdHBwse1BQkLP98ccfcqs0aNBAdq8fRT958mRnq1+/vtxevHhR9tOnTzvbypUr5bZx48ay//77787Wp08fuR05cqTsoaGhzpYkSRK5LVasmLN16dJFbhMkSCD7vn37nC1TpkxymyhRItkvXbrkbB07dpTbF0WUKFFkX7VqlbP9+OOPcnvr1i3ZBw0a5Gw5cuSQW6Vo0aKylypVSvapU6c6W9y4ceX2u+++k71v377OtmXLFrnNnj277BEiuP+tNmLEiHLr9bibN2/ubF6fz0OHDjnblClT5HbYsGGyx48f39natGkjt1myZJF98eLFzvbaa6/J7YtEHeNm+nXH63jYtGmT7NmyZXO2devWya16vQwEAnI7e/Zs2X/++WdnU89nM7OdO3fK3rJlS2dT1x5mZp07d5a9d+/ezvbee+/JrTqWzPTrYZkyZeT22LFjzlaxYkW5nTRpkuzqGrZIkSJyO2vWLNl37NjhbPHixZPbF0VYWJjs9+/fd7YUKVLIrdd7APV8V89lM32MfvXVV3IbJ04c2ceNG+dsAwcOlNu7d+/Knjp1amc7fPiw3HqdT7/88ktnGzVqlNzmy5dP9lq1ajlb2bJl5XbmzJnOdvPmTbndvn277OraZsWKFXKr3j+YmX300UfOVq9ePbl9UnyHHQAAAAAAAOAj3LADAAAAAAAAfIQbdgAAAAAAAICPcMMOAAAAAAAA8BFu2AEAAAAAAAA+wg07AAAAAAAAwEe4YQcAAAAAAAD4SFAgEAg87wcBAAAAAAAA4F/4DjsAAAAAAADAR7hhBwAAAAAAAPgIN+wAAAAAAAAAH+GGHQAAAAAAAOAj3LADAAAAAAAAfIQbdgAAAAAAAICPcMMOAAAAAAAA8BFu2AEAAAAAAAA+wg07AAAAAAAAwEf+Py/QwGKOhDycAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1600x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = next(iter(train_loader))[0][0].squeeze()\n",
    "label = next(iter(train_loader))[1][0].squeeze()\n",
    "\n",
    "x_start = image\n",
    "\n",
    "gaussian_diffusion = GaussianDiffusion(timesteps=500, beta_schedule='linear')\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "for idx, t in enumerate([0, 100, 300, 400, 499]):\n",
    "    x_noisy = gaussian_diffusion.q_sample(x_start.to(device), t=torch.tensor([t]).to(device))\n",
    "    noisy_image = (x_noisy.squeeze() + 1) * 127.5\n",
    "    if idx==0:\n",
    "        noisy_image = (x_start.squeeze() + 1) * 127.5\n",
    "    noisy_image = noisy_image.cpu().numpy().astype(np.uint8)\n",
    "    plt.subplot(1, 5, 1 + idx)\n",
    "    plt.imshow(noisy_image, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"t={t}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "epochs = 10\n",
    "p_uncound = 0.2\n",
    "len_data = len(train_loader)\n",
    "time_end = time.time()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, (images, labels) in enumerate(train_loader):     \n",
    "        time_start = time_end\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_size = images.shape[0]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # random generate mask\n",
    "        z_uncound = torch.rand(batch_size)\n",
    "        batch_mask = (z_uncound>p_uncound).int().to(device)\n",
    "        \n",
    "        # sample t uniformally for every example in the batch\n",
    "        t = torch.randint(0, timesteps, (batch_size,), device=device).long()\n",
    "        \n",
    "        loss = gaussian_diffusion.train_losses(model, images, t, labels, batch_mask)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            time_end = time.time()\n",
    "            print(\"Epoch{}/{}\\t  Step{}/{}\\t Loss {:.4f}\\t Time {:.2f}\".format(epoch+1, epochs, step+1, len_data, loss.item(), time_end-time_start))\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./saved_models'):\n",
    "    os.mkdir('./saved_models')\n",
    "torch.save(model, './saved_models/Classifier_free_DDIM_MNIST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./saved_models/Classifier_free_DDIM_MNIST.h5')\n",
    "gaussian_diffusion = GaussianDiffusion(timesteps=500, beta_schedule='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = gaussian_diffusion.sample(model, 28, batch_size=64, channels=1, n_class=10, w=2, mode='random', clip_denoised=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new images\n",
    "fig = plt.figure(figsize=(12, 12), constrained_layout=True)\n",
    "gs = fig.add_gridspec(8, 8)\n",
    "\n",
    "imgs = generated_images[-1].reshape(8, 8, 28, 28)\n",
    "for n_row in range(8):\n",
    "    for n_col in range(8):\n",
    "        f_ax = fig.add_subplot(gs[n_row, n_col])\n",
    "        f_ax.imshow((imgs[n_row, n_col]+1.0) * 255 / 2, cmap=\"gray\")\n",
    "        f_ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddim_generated_images = gaussian_diffusion.ddim_sample(model, 28, batch_size=64, channels=1, ddim_timesteps=50, n_class=10,\n",
    "                                                       w=2, mode='random', ddim_discr_method='quad', ddim_eta=0.0, clip_denoised=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddim generate new images\n",
    "fig = plt.figure(figsize=(12, 12), constrained_layout=True)\n",
    "gs = fig.add_gridspec(8, 8)\n",
    "\n",
    "imgs = ddim_generated_images.reshape(8, 8, 28, 28)\n",
    "for n_row in range(8):\n",
    "    for n_col in range(8):\n",
    "        f_ax = fig.add_subplot(gs[n_row, n_col])\n",
    "        f_ax.imshow((imgs[n_row, n_col]+1.0) * 255 / 2, cmap=\"gray\")\n",
    "        f_ax.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
