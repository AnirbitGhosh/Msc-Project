{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset to hold input and conditional image pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDataset(Dataset):\n",
    "    def __init__(self, img_path, img_ext=\"mpy\"):\n",
    "        self.img_ext = img_ext  # Correct variable name for consistency\n",
    "        self.image_files = [os.path.join(img_path, f) for f in os.listdir(img_path)]\n",
    "        self.images = []\n",
    "        self.inputs = []\n",
    "        self.conditionals = []\n",
    "        \n",
    "        for file in self.image_files:\n",
    "            filepath = os.path.join(img_path, file)\n",
    "             # Load image on demand\n",
    "            with open(filepath, 'rb') as f:\n",
    "                img_arr = pickle.load(f)  # Assume images are stored as pickled numpy arrays\n",
    "            \n",
    "            self.images = img_arr\n",
    "    \n",
    "            for idx in range(4, len(self.images)):\n",
    "                self.inputs.append(self.images[idx])\n",
    "                self.conditionals.append(self.images[idx - 4])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.inputs[index]\n",
    "        conditional = self.conditionals[index]\n",
    "        \n",
    "        # Convert numpy array to tensor\n",
    "        img_tensor = torchvision.transforms.ToTensor()(img)\n",
    "        cond_tensor = torchvision.transforms.ToTensor()(conditional)\n",
    "        \n",
    "        # Normalize the tensor\n",
    "        img_tensor = (2 * img_tensor) - 1\n",
    "        cond_tensor = (2 * cond_tensor) - 1\n",
    "        return img_tensor, cond_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"C:/Users/Anirbit/Desktop/MSc/Ind Project/Msc-Project/data\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# create dataset\n",
    "train_ratio = 0.8\n",
    "test_ratio = 1 - train_ratio\n",
    "\n",
    "data = ConditionalDataset(os.path.join(DATA_DIR, \"bin_frames\"))\n",
    "\n",
    "train_size = int(train_ratio * (len(data)))\n",
    "test_size = (len(data)) - train_size\n",
    "\n",
    "train_data, test_data = random_split(data, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGhCAYAAADbf0s2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh4ElEQVR4nO3df3BV9Z3/8dcNl1zCj3uvCeXeRBJMXSq4oIugMdLZ/sGdYuuorWy7ZdItSxkd26AgM1tkHejsODRM3e1ubV3ZdqauM0WpzAgos2yXDRTKTgwYQEU00JpCCtywijk3/MgPct/7R7+er1cDBLjJ/dzk+Zh5z5RzTk4+nxnMszf3kATMzAQAgIMKcr0AAAAuhkgBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJyVs0g988wzuuGGGzRq1ChVVVVpz549uVoKAMBROYnUr371Ky1btkzf//73tW/fPt16662aO3euTp06lYvlAAAcFcjFD5itqqrS7bffrp/+9KeSpHQ6rfLycj3yyCN6/PHHL/vx6XRaJ06c0Lhx4xQIBAZ6uQCALDMzdXR0qKysTAUFF3+9FBzENUmSuru71dTUpBUrVvjHCgoKlEgk1NDQ0OfHdHV1qaury//z8ePHdfPNNw/4WgEAA6u1tVUTJ0686PlB/3bf+++/r97eXsVisYzjsVhMyWSyz4+pq6tTJBLxh0ABwNAwbty4S57Pi6f7VqxYIc/z/Gltbc31kgAAWXC5t2wG/dt948eP14gRI9TW1pZxvK2tTfF4vM+PCYVCCoVCg7E8AIBDBv2VVGFhoWbOnKn6+nr/WDqdVn19vaqrqwd7OQAAhw36KylJWrZsmRYsWKBZs2bpjjvu0L/8y7/o7NmzWrhwYS6WAwBwVE4i9dd//df63//9X61atUrJZFJ/8Rd/of/8z//81MMUAIDhLSf/TupapVIpRSKRXC8DAHCNPM9TOBy+6Pm8eLoPADA8ESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJyV9UjV1dXp9ttv17hx4zRhwgR95StfUXNzc8Y1nZ2dqq2tVUlJicaOHat58+apra0t20sBAOS5rEdq586dqq2t1WuvvaZt27app6dHX/ziF3X27Fn/mscee0yvvvqqNmzYoJ07d+rEiRN64IEHsr0UAEC+swF26tQpk2Q7d+40M7P29nYbOXKkbdiwwb/mnXfeMUnW0NDQr3t6nmeSGIZhmDwfz/Mu+fV+wN+T8jxPklRcXCxJampqUk9PjxKJhH/NlClTVFFRoYaGhj7v0dXVpVQqlTEAgKFvQCOVTqe1dOlSzZ49W9OmTZMkJZNJFRYWKhqNZlwbi8WUTCb7vE9dXZ0ikYg/5eXlA7lsAIAjBjRStbW1OnjwoNavX39N91mxYoU8z/OntbU1SysEALgsOFA3Xrx4sbZs2aJdu3Zp4sSJ/vF4PK7u7m61t7dnvJpqa2tTPB7v816hUEihUGiglgoAcFTWX0mZmRYvXqyNGzdq+/btqqyszDg/c+ZMjRw5UvX19f6x5uZmHTt2TNXV1dleDgAgj2X9lVRtba1eeOEFbd68WePGjfPfZ4pEIioqKlIkEtGiRYu0bNkyFRcXKxwO65FHHlF1dbXuvPPObC8HAJDPrvrZ8ovQRR4zfO655/xrzp8/b9/97nftuuuus9GjR9tXv/pVO3nyZL8/B4+gMwzDDI253CPogf8XlrySSqUUiURyvQwAwDXyPE/hcPii5/nZfQAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOItIAQCcRaQAAM4iUgAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOItIAQCcRaQAAM4iUgAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOItIAQCcRaQAAM4iUgAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOItIAQCcRaQAAM4iUgAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOItIAQCcRaQAAM4iUgAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOGvAI7VmzRoFAgEtXbrUP9bZ2ana2lqVlJRo7Nixmjdvntra2gZ6KQCAPDOgkdq7d6/+7d/+TbfcckvG8ccee0yvvvqqNmzYoJ07d+rEiRN64IEHBnIpAIB8ZAOko6PDJk+ebNu2bbMvfOELtmTJEjMza29vt5EjR9qGDRv8a9955x2TZA0NDf26t+d5JolhGIbJ8/E875Jf7wfslVRtba3uueceJRKJjONNTU3q6enJOD5lyhRVVFSooaFhoJYDAMhDwYG46fr167Vv3z7t3bv3U+eSyaQKCwsVjUYzjsdiMSWTyT7v19XVpa6uLv/PqVQqq+sFALgp66+kWltbtWTJEq1bt06jRo3Kyj3r6uoUiUT8KS8vz8p9AQBuy3qkmpqadOrUKd12220KBoMKBoPauXOnnn76aQWDQcViMXV3d6u9vT3j49ra2hSPx/u854oVK+R5nj+tra3ZXjYAwEFZ/3bfnDlz9NZbb2UcW7hwoaZMmaLly5ervLxcI0eOVH19vebNmydJam5u1rFjx1RdXd3nPUOhkEKhULaXCgBwXNYjNW7cOE2bNi3j2JgxY1RSUuIfX7RokZYtW6bi4mKFw2E98sgjqq6u1p133pnt5QAA8tiAPDhxOf/8z/+sgoICzZs3T11dXZo7d67+9V//NRdLAQA4LGBmlutFXKlUKqVIJJLrZQAArpHneQqHwxc9z8/uAwA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKGOICgUCulwBcNSIFDGEfBYpQIV8RKWCIIkwYCoK5XgCAwVVQUKBQKKRgMKhgMKhRo0YpGAzq/Pnz8jxPPT09uV4i4CNSwDARCARkZhozZoxuvPFGfeYzn9H48eN18803a/z48Tp48KBeeeUVtba25nqpgI9IAcPMqFGjNGnSJFVWVmrSpElKJBK64YYb9F//9V/6n//5HyIFpxApYIgyM/99qWAwqHA4rNGjR6ukpESlpaWKx+MaP368xowZo8LCQkUiEVVWVqqzs1OpVErvv/++uru7/fv15z0uMxuw/WB4IlLAEPZRqMaNG6e77rpLU6dO1XXXXadbbrlFZWVlGj16tIqLixUIBHTTTTfp4Ycf1ocffqiGhga99NJLOnnyZK63gGGOSAFDnJmpqKhIn/vc5zR79mxFIhHddNNNisViMjN/SktLdf311yudTsvMtHXrViKFnCNSwDDQ3d2ttrY2/f73v9dnPvMZlZeXS8r8Fl5vb6/OnTunCxcu6Pz580qn07laLuAjUsAw0NHRod27d+vQoUP63Oc+p4qKClVWVkr6U6gCgYA6Ojr0xz/+UWfOnNHJkyd14cIFFRT86Z9S8l4TcoVIAUPUx18ldXZ26g9/+IP+8Ic/qLe3V57n+e9XfXRdd3e3PvzwQ7W3tyuVSimdTvuPrQO5QqSAYebMmTN66623Mp7qKywsVDKZ1KFDh/Thhx/q2LFj6urqyvVSAQUsD/9vUiqVUiQSyfUyAKd9/JXUx/8zHz16tCoqKhSNRjV+/HhNnTpVJSUl+uMf/6gDBw7o/fff15kzZ/xH0K/kS0QefjlBjnmep3A4fNHzvJIChpD+/Fumc+fO6d1335UkxeNxSVJpaamOHTumd999Vx988MGArhG4EkQKGMIu98qms7NTyWRS3d3dn/rHu5e6Dz+8FoOFSAHD2NmzZ3X48GGNHDlSPT09OnfuHN+yg1OIFDDMfPxV0IULF9TR0ZHD1QCXxu+TAgA4i0gBw0h/3kvi/Sa4hG/3AUPY1QaHUMEVvJICADiLSAEAnEWkAADOIlIAAGcNSKSOHz+ub37zmyopKVFRUZGmT5+u119/3T9vZlq1apVKS0tVVFSkRCKhI0eODMRSAAB5LOuR+vDDDzV79myNHDlSW7du1aFDh/RP//RPuu666/xrfvjDH+rpp5/W2rVr1djYqDFjxmju3Lnq7OzM9nIAAPnMsmz58uX2+c9//qLn0+m0xeNxe+qpp/xj7e3tFgqF7MUXX+zX5/A8zyQxDPOJCQQCOZ1c75/Jv/E875Jf77P+SuqVV17RrFmz9LWvfU0TJkzQjBkz9POf/9w/39LSomQyqUQi4R+LRCKqqqpSQ0NDn/fs6upSKpXKGADA0Jf1SL333nt69tlnNXnyZP3617/Wd77zHT366KN6/vnnJUnJZFKSFIvFMj4uFov55z6prq5OkUjEn/Ly8mwvGwDgoKxHKp1O67bbbtMPfvADzZgxQw899JAefPBBrV279qrvuWLFCnme509ra2sWVwwAcFXWI1VaWqqbb74549jUqVN17NgxSf//l6y1tbVlXNPW1uaf+6RQKKRwOJwxAIChL+uRmj17tpqbmzOOHT58WJMmTZIkVVZWKh6Pq76+3j+fSqXU2Nio6urqbC8HAJDP+vfMXv/t2bPHgsGgrV692o4cOWLr1q2z0aNH2y9/+Uv/mjVr1lg0GrXNmzfbm2++affff79VVlba+fPn+/U5eLqPYfoenu5j8m0u93Rf1iNlZvbqq6/atGnTLBQK2ZQpU+xnP/tZxvl0Om0rV660WCxmoVDI5syZY83Nzf2+P5FimL6HSDH5NpeLVMAs/35XdCqVUiQSyfUyAOfk+lds5OGXE+SY53mXfM6An90HAHAWkQIAOIvfzAsMIXy7DUMNr6QAAM4iUgAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOItIAQCcRaQAAM4iUgAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOItIAQCcRaQAAM4iUgAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOItIAQCcRaQAAM4iUgAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOItIAQCcRaQAAM4iUgAAZxEpAICziBQAwFlECgDgLCIFAHAWkQIAOItIAQCcRaQAAM4iUgAAZxEpAICziBQAwFlZj1Rvb69WrlypyspKFRUV6cYbb9STTz4pM/OvMTOtWrVKpaWlKioqUiKR0JEjR7K9FABAvrMsW716tZWUlNiWLVuspaXFNmzYYGPHjrUf//jH/jVr1qyxSCRimzZtsjfeeMPuu+8+q6ystPPnz/frc3ieZ5IYhmGYPB/P8y759T7rkbrnnnvs29/+dsaxBx54wGpqaszMLJ1OWzwet6eeeso/397ebqFQyF588cV+fQ4ixTAMMzTmcpHK+rf77rrrLtXX1+vw4cOSpDfeeEO7d+/Wl770JUlSS0uLksmkEomE/zGRSERVVVVqaGjo855dXV1KpVIZAwAY+oLZvuHjjz+uVCqlKVOmaMSIEert7dXq1atVU1MjSUomk5KkWCyW8XGxWMw/90l1dXX6h3/4h2wvFQDguKy/knrppZe0bt06vfDCC9q3b5+ef/55/eM//qOef/75q77nihUr5HmeP62trVlcMQDAWVf4ltNlTZw40X76059mHHvyySftpptuMjOz3//+9ybJ9u/fn3HNX/7lX9qjjz7ar8/Be1IMwzBDYwb9Palz586poCDztiNGjFA6nZYkVVZWKh6Pq76+3j+fSqXU2Nio6urqbC8HAJDP+v8aqX8WLFhg119/vf8I+ssvv2zjx4+3733ve/41a9assWg0aps3b7Y333zT7r//fh5BZxiGGYYz6I+gp1IpW7JkiVVUVNioUaPss5/9rD3xxBPW1dXlX5NOp23lypUWi8UsFArZnDlzrLm5ud+fg0gxDMMMjblcpAJmH/tREHkilUopEonkehkAgGvkeZ7C4fBFz/Oz+wAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA464ojtWvXLt17770qKytTIBDQpk2bMs6bmVatWqXS0lIVFRUpkUjoyJEjGdecPn1aNTU1CofDikajWrRokc6cOXNNGwEADD1XHKmzZ8/q1ltv1TPPPNPn+R/+8Id6+umntXbtWjU2NmrMmDGaO3euOjs7/Wtqamr09ttva9u2bdqyZYt27dqlhx566Op3AQAYmuwaSLKNGzf6f06n0xaPx+2pp57yj7W3t1soFLIXX3zRzMwOHTpkkmzv3r3+NVu3brVAIGDHjx/v1+f1PM8kMQzDMHk+nudd8ut9Vt+TamlpUTKZVCKR8I9FIhFVVVWpoaFBktTQ0KBoNKpZs2b51yQSCRUUFKixsbHP+3Z1dSmVSmUMAGDoy2qkksmkJCkWi2Ucj8Vi/rlkMqkJEyZknA8GgyouLvav+aS6ujpFIhF/ysvLs7lsAICj8uLpvhUrVsjzPH9aW1tzvSQAwCDIaqTi8bgkqa2tLeN4W1ubfy4ej+vUqVMZ5y9cuKDTp0/713xSKBRSOBzOGADA0JfVSFVWVioej6u+vt4/lkql1NjYqOrqaklSdXW12tvb1dTU5F+zfft2pdNpVVVVZXM5AIB8dwUP85mZWUdHh+3fv9/2799vkuxHP/qR7d+/344ePWpmZmvWrLFoNGqbN2+2N9980+6//36rrKy08+fP+/e4++67bcaMGdbY2Gi7d++2yZMn2/z58/u9Bp7uYxiGGRpzuaf7rjhSO3bs6PMTLViwwMz+9Bj6ypUrLRaLWSgUsjlz5lhzc3PGPT744AObP3++jR071sLhsC1cuNA6OjqIFMMwzDCby0UqYGamPJNKpRSJRHK9DADANfI875LPGeTF030AgOGJSAEAnEWkAADOIlIAAGcRKQCAs4gUAMBZRAoA4CwiBQBwFpECADiLSAEAnEWkAADOIlIAAGcRKQCAs4gUAMBZRAoA4CwiBQBwFpECADiLSAEAnEWkAADOIlIAAGcRKQCAs4gUAMBZRAoA4CwiBQBwFpECADiLSAEAnEWkAADOIlIAAGcRKQCAs4gUAMBZRAoA4CwiBQBwFpECADiLSAEAnEWkAADOIlIAAGcRKQCAs4gUAMBZRAoA4CwiBQBwFpECADiLSAEAnEWkAADOIlIAAGcRKQCAs4gUAMBZVxypXbt26d5771VZWZkCgYA2bdrkn+vp6dHy5cs1ffp0jRkzRmVlZfrWt76lEydOZNzj9OnTqqmpUTgcVjQa1aJFi3TmzJlr3gwAYGi54kidPXtWt956q5555plPnTt37pz27dunlStXat++fXr55ZfV3Nys++67L+O6mpoavf3229q2bZu2bNmiXbt26aGHHrr6XQAAhia7BpJs48aNl7xmz549JsmOHj1qZmaHDh0ySbZ3717/mq1bt1ogELDjx4/36/N6nmeSGIZhmDwfz/Mu+fV+wN+T8jxPgUBA0WhUktTQ0KBoNKpZs2b51yQSCRUUFKixsXGglwMAyCPBgbx5Z2enli9frvnz5yscDkuSksmkJkyYkLmIYFDFxcVKJpN93qerq0tdXV3+n1Op1MAtGgDgjAF7JdXT06Ovf/3rMjM9++yz13Svuro6RSIRf8rLy7O0SgCAywYkUh8F6ujRo9q2bZv/KkqS4vG4Tp06lXH9hQsXdPr0acXj8T7vt2LFCnme509ra+tALBsA4Jisf7vvo0AdOXJEO3bsUElJScb56upqtbe3q6mpSTNnzpQkbd++Xel0WlVVVX3eMxQKKRQKZXupAADHXXGkzpw5o9/97nf+n1taWnTgwAEVFxertLRUf/VXf6V9+/Zpy5Yt6u3t9d9nKi4uVmFhoaZOnaq7775bDz74oNauXauenh4tXrxY3/jGN1RWVpa9nQEA8l+/nvn+mB07dvT5GOGCBQuspaXloo8Z7tixw7/HBx98YPPnz7exY8daOBy2hQsXWkdHR7/XwCPoDMMwQ2Mu9wh6wMxMeSaVSikSieR6GQCAa+R5XsZzC5/Ez+4DADiLSAEAnEWkAADOIlIAAGcRKQCAs4gUAMBZRAoA4CwiBQBwFpECADiLSAEAnEWkAADOIlIAAGcRKQCAs4gUAMBZeRmpPPztIgCAPlzu63leRqqjoyPXSwAAZMHlvp7n5S89TKfTOnHihMxMFRUVam1tveQvzcpnqVRK5eXlQ3qPEvscaobDPofDHqWB26eZqaOjQ2VlZSoouPjrpWDWPuMgKigo0MSJE5VKpSRJ4XB4SP8lkYbHHiX2OdQMh30Ohz1KA7PP/vyG9bz8dh8AYHggUgAAZ+V1pEKhkL7//e8rFArleikDZjjsUWKfQ81w2Odw2KOU+33m5YMTAIDhIa9fSQEAhjYiBQBwFpECADiLSAEAnJW3kXrmmWd0ww03aNSoUaqqqtKePXtyvaRrUldXp9tvv13jxo3ThAkT9JWvfEXNzc0Z13R2dqq2tlYlJSUaO3as5s2bp7a2thyt+NqtWbNGgUBAS5cu9Y8NlT0eP35c3/zmN1VSUqKioiJNnz5dr7/+un/ezLRq1SqVlpaqqKhIiURCR44cyeGKr1xvb69WrlypyspKFRUV6cYbb9STTz6Z8bPY8nGfu3bt0r333quysjIFAgFt2rQp43x/9nT69GnV1NQoHA4rGo1q0aJFOnPmzCDu4tIutceenh4tX75c06dP15gxY1RWVqZvfetbOnHiRMY9Bm2PlofWr19vhYWF9otf/MLefvtte/DBBy0ajVpbW1uul3bV5s6da88995wdPHjQDhw4YF/+8petoqLCzpw541/z8MMPW3l5udXX19vrr79ud955p9111105XPXV27Nnj91www12yy232JIlS/zjQ2GPp0+ftkmTJtnf/u3fWmNjo7333nv261//2n73u9/516xZs8YikYht2rTJ3njjDbvvvvussrLSzp8/n8OVX5nVq1dbSUmJbdmyxVpaWmzDhg02duxY+/GPf+xfk4/7/I//+A974okn7OWXXzZJtnHjxozz/dnT3Xffbbfeequ99tpr9tvf/tb+7M/+zObPnz/IO7m4S+2xvb3dEomE/epXv7J3333XGhoa7I477rCZM2dm3GOw9piXkbrjjjustrbW/3Nvb6+VlZVZXV1dDleVXadOnTJJtnPnTjP701+ckSNH2oYNG/xr3nnnHZNkDQ0NuVrmVeno6LDJkyfbtm3b7Atf+IIfqaGyx+XLl9vnP//5i55Pp9MWj8ftqaee8o+1t7dbKBSyF198cTCWmBX33HOPffvb38449sADD1hNTY2ZDY19fvILeH/2dOjQIZNke/fu9a/ZunWrBQIBO378+KCtvb/6CvEn7dmzxyTZ0aNHzWxw95h33+7r7u5WU1OTEomEf6ygoECJREINDQ05XFl2eZ4nSSouLpYkNTU1qaenJ2PfU6ZMUUVFRd7tu7a2Vvfcc0/GXqShs8dXXnlFs2bN0te+9jVNmDBBM2bM0M9//nP/fEtLi5LJZMY+I5GIqqqq8mqfd911l+rr63X48GFJ0htvvKHdu3frS1/6kqShs8+P68+eGhoaFI1GNWvWLP+aRCKhgoICNTY2Dvqas8HzPAUCAUWjUUmDu8e8+wGz77//vnp7exWLxTKOx2IxvfvuuzlaVXal02ktXbpUs2fP1rRp0yRJyWRShYWF/l+Sj8RiMSWTyRys8uqsX79e+/bt0969ez91bqjs8b333tOzzz6rZcuW6e///u+1d+9ePfrooyosLNSCBQv8vfT1dzif9vn4448rlUppypQpGjFihHp7e7V69WrV1NRI0pDZ58f1Z0/JZFITJkzIOB8MBlVcXJyX++7s7NTy5cs1f/58/wfMDuYe8y5Sw0Ftba0OHjyo3bt353opWdXa2qolS5Zo27ZtGjVqVK6XM2DS6bRmzZqlH/zgB5KkGTNm6ODBg1q7dq0WLFiQ49Vlz0svvaR169bphRde0J//+Z/rwIEDWrp0qcrKyobUPoeznp4eff3rX5eZ6dlnn83JGvLu233jx4/XiBEjPvXEV1tbm+LxeI5WlT2LFy/Wli1btGPHDk2cONE/Ho/H1d3drfb29ozr82nfTU1NOnXqlG677TYFg0EFg0Ht3LlTTz/9tILBoGKxWN7vUZJKS0t18803ZxybOnWqjh07Jkn+XvL97/Df/d3f6fHHH9c3vvENTZ8+XX/zN3+jxx57THV1dZKGzj4/rj97isfjOnXqVMb5Cxcu6PTp03m1748CdfToUW3bti3j13QM5h7zLlKFhYWaOXOm6uvr/WPpdFr19fWqrq7O4cqujZlp8eLF2rhxo7Zv367KysqM8zNnztTIkSMz9t3c3Kxjx47lzb7nzJmjt956SwcOHPBn1qxZqqmp8f93vu9RkmbPnv2pfz5w+PBhTZo0SZJUWVmpeDyesc9UKqXGxsa82ue5c+c+9cvqRowYoXQ6LWno7PPj+rOn6upqtbe3q6mpyb9m+/btSqfTqqqqGvQ1X42PAnXkyBH993//t0pKSjLOD+oes/oYxiBZv369hUIh+/d//3c7dOiQPfTQQxaNRi2ZTOZ6aVftO9/5jkUiEfvNb35jJ0+e9OfcuXP+NQ8//LBVVFTY9u3b7fXXX7fq6mqrrq7O4aqv3cef7jMbGnvcs2ePBYNBW716tR05csTWrVtno0ePtl/+8pf+NWvWrLFoNGqbN2+2N9980+6//37nH83+pAULFtj111/vP4L+8ssv2/jx4+173/uef00+7rOjo8P2799v+/fvN0n2ox/9yPbv3+8/2dafPd199902Y8YMa2xstN27d9vkyZOdegT9Unvs7u62++67zyZOnGgHDhzI+HrU1dXl32Ow9piXkTIz+8lPfmIVFRVWWFhod9xxh7322mu5XtI1kdTnPPfcc/4158+ft+9+97t23XXX2ejRo+2rX/2qnTx5MneLzoJPRmqo7PHVV1+1adOmWSgUsilTptjPfvazjPPpdNpWrlxpsVjMQqGQzZkzx5qbm3O02quTSqVsyZIlVlFRYaNGjbLPfvaz9sQTT2R8IcvHfe7YsaPP/xYXLFhgZv3b0wcffGDz58+3sWPHWjgctoULF1pHR0cOdtO3S+2xpaXlol+PduzY4d9jsPbIr+oAADgr796TAgAMH0QKAOAsIgUAcBaRAgA4i0gBAJxFpAAAziJSAABnESkAgLOIFADAWUQKAOAsIgUAcBaRAgA46/8A4w091RPlMQgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(idx)\n",
    "    plt.imshow(x[0].permute(1, 2, 0), cmap='gray')\n",
    "    plt.show()\n",
    "    plt.imshow(y[0].permute(1, 2, 0), cmap='gray')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Denoising Diffusion Model \n",
    "\n",
    "#### Noise Scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNoiseScheduler:\n",
    "    def __init__(self, num_timesteps, beta_start, beta_end, device):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        \n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alpha_cum_prod = torch.cumprod(self.alphas, dim=0).to(device)\n",
    "        self.sqrt_alpha_cum_prod = torch.sqrt(self.alpha_cum_prod).to(device)\n",
    "        self.sqrt_one_minus_alpha_cum_prod = torch.sqrt(1. - self.alpha_cum_prod).to(device)\n",
    "        \n",
    "    def add_noise(self, original, noise, t):\n",
    "        original_shape = original.shape\n",
    "        batch_size = original_shape[0]\n",
    "        \n",
    "        sqrt_alpha_cum_prod = self.sqrt_alpha_cum_prod[t].reshape(batch_size)\n",
    "        sqrt_one_minus_alpha_cum_prod = self.sqrt_one_minus_alpha_cum_prod[t].reshape(batch_size)\n",
    "        \n",
    "        for _ in range(len(original_shape) - 1):\n",
    "            sqrt_alpha_cum_prod = sqrt_alpha_cum_prod.unsqueeze(-1)\n",
    "            sqrt_one_minus_alpha_cum_prod = sqrt_one_minus_alpha_cum_prod.unsqueeze(-1)\n",
    "        \n",
    "        return sqrt_alpha_cum_prod  * original  + sqrt_one_minus_alpha_cum_prod * noise\n",
    "    \n",
    "    \n",
    "    def sample_prev_timestep(self, xt, noise_pred, t):\n",
    "        \"\"\"\n",
    "            Use the noise prediction by model to get\n",
    "            xt-1 using xt and the noise predicted\n",
    "        :param xt: current timestep sample\n",
    "        :param noise_pred: model noise prediction\n",
    "        :param t: current timestep we are at\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x0 = ((xt - (self.sqrt_one_minus_alpha_cum_prod.to(xt.device)[t] * noise_pred)) /\n",
    "              torch.sqrt(self.alpha_cum_prod.to(xt.device)[t]))\n",
    "        x0 = torch.clamp(x0, -1., 1.)\n",
    "        \n",
    "        mean = xt - ((self.betas.to(xt.device)[t]) * noise_pred) / (self.sqrt_one_minus_alpha_cum_prod.to(xt.device)[t])\n",
    "        mean = mean / torch.sqrt(self.alphas.to(xt.device)[t])\n",
    "        \n",
    "        if t == 0:\n",
    "            return mean, x0\n",
    "        else:\n",
    "            variance = (1 - self.alpha_cum_prod.to(xt.device)[t - 1]) / (1.0 - self.alpha_cum_prod.to(xt.device)[t])\n",
    "            variance = variance * self.betas.to(xt.device)[t]\n",
    "            sigma = variance ** 0.5\n",
    "            z = torch.randn(xt.shape).to(xt.device)\n",
    "            \n",
    "            # OR\n",
    "            # variance = self.betas[t]\n",
    "            # sigma = variance ** 0.5\n",
    "            # z = torch.randn(xt.shape).to(xt.device)\n",
    "            return mean + sigma * z, x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model component blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_embedding(time_steps, t_emb_dim):\n",
    "    factor = 10000 ** ((torch.arange(\n",
    "        start=0, end=t_emb_dim//2, device=time_steps.device) / (t_emb_dim // 2)\n",
    "    ))\n",
    "    t_emb = time_steps[:, None].repeat(1, t_emb_dim // 2) / factor\n",
    "    t_emb = torch.cat([torch.sin(t_emb), torch.cos(t_emb)], dim=-1)\n",
    "    return t_emb\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, t_emb_dim, down_sample, num_heads):\n",
    "        super().__init__()\n",
    "        self.down_sample = down_sample\n",
    "        self.resnet_conv_first = nn.Sequential(\n",
    "            nn.GroupNorm(8, in_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.t_emb_layers = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(t_emb_dim, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.resnet_conv_second = nn.Sequential(\n",
    "            nn.GroupNorm(8, out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.attention_norm = nn.GroupNorm(8, out_channels)\n",
    "        self.attention = nn.MultiheadAttention(out_channels, num_heads, batch_first=True)\n",
    "        self.residual_input_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.down_sample_conv = nn.Conv2d(out_channels, out_channels, kernel_size=4,\n",
    "                                          stride=2, padding=1) if self.down_sample else nn.Identity()\n",
    "        \n",
    "    def forward(self, x, t_emb):\n",
    "        out = x\n",
    "        # Resnet Block\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first(out)\n",
    "        out = out + self.t_emb_layers(t_emb)[:, :, None, None]\n",
    "        out = self.resnet_conv_second(out)\n",
    "        out = out + self.residual_input_conv(resnet_input)\n",
    "        \n",
    "        # Attention Block\n",
    "        # batch_size, channels, h, w = out.shape\n",
    "        # in_attn = out.reshape(batch_size, channels, h*w)\n",
    "        # in_attn = self.attention_norm(in_attn)\n",
    "        # in_attn = in_attn.transpose(1, 2)\n",
    "        # out_attn, _ = self.attention(in_attn, in_attn, in_attn)\n",
    "        # out_attn = out_attn.transpose(1, 2).reshape(batch_size, channels, h, w)\n",
    "        # out = out + out_attn\n",
    "        \n",
    "        out = self.down_sample_conv(out)\n",
    "        return out\n",
    "    \n",
    "class MidBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, t_emb_dim,  num_heads):\n",
    "        super().__init__()\n",
    "        self.resnet_conv_first = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, in_channels),\n",
    "                nn.SiLU(),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.SiLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            )\n",
    "        ])\n",
    "        self.t_emb_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(t_emb_dim, out_channels)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.SiLU(), \n",
    "                nn.Linear(t_emb_dim, out_channels)\n",
    "            )\n",
    "        ])\n",
    "        self.resnet_conv_second = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.SiLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.SiLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            )\n",
    "        ])\n",
    "        self.attention_norm = nn.GroupNorm(8, out_channels)\n",
    "        self.attention = nn.MultiheadAttention(out_channels, num_heads, batch_first=True)\n",
    "        self.residual_input_conv = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        out = x \n",
    "        #first resnet block\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first[0](out)\n",
    "        out = out + self.t_emb_layers[0](t_emb)[:,:,None,None]\n",
    "        out = self.resnet_conv_second[0](out)\n",
    "        out = out + self.residual_input_conv[0](resnet_input)\n",
    "        \n",
    "        # attention block\n",
    "        # batch_size, channels, h, w  = out.shape\n",
    "        # in_attn = out.reshape(batch_size, channels, h*w)\n",
    "        # in_attn = self.attention_norm(in_attn)\n",
    "        # in_attn = in_attn.transpose(1, 2)\n",
    "        # out_attn, _ = self.attention(in_attn, in_attn, in_attn)\n",
    "        # out_attn = out_attn.transpose(1, 2).reshape(batch_size, channels, h, w)\n",
    "        # out = out + out_attn\n",
    "        \n",
    "        # second resnet block\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first[1](out)\n",
    "        out = out + self.t_emb_layers[1](t_emb)[:,:,None,None]\n",
    "        out = self.resnet_conv_second[1](out)\n",
    "        out = out + self.residual_input_conv[1](resnet_input)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, t_emb_dim, up_sample, num_heads):\n",
    "        super().__init__()\n",
    "        self.up_sample = up_sample\n",
    "        self.resnet_conv_first = nn.Sequential(\n",
    "            nn.GroupNorm(8, in_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.t_emb_layers = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(t_emb_dim, out_channels)\n",
    "        )\n",
    "        self.resnet_conv_second = nn.Sequential(\n",
    "            nn.GroupNorm(8, out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.attention_norm = nn.GroupNorm(8, out_channels)\n",
    "        self.attention = nn.MultiheadAttention(out_channels, num_heads, batch_first=True)\n",
    "        self.residual_input_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.up_sample_conv = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=4, \n",
    "                                                    stride=2, padding=1) if self.up_sample else nn.Identity()\n",
    "        \n",
    "    def forward(self, x, out_down, t_emb):\n",
    "        x = self.up_sample_conv(x)\n",
    "        x = torch.cat([x, out_down], dim=1)\n",
    "        \n",
    "        # Resnet Block\n",
    "        out = x\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first(out)\n",
    "        out = out + self.t_emb_layers(t_emb)[:, :, None, None]\n",
    "        out = self.resnet_conv_second(out)\n",
    "        out = out + self.residual_input_conv(resnet_input)\n",
    "        \n",
    "        # Attention Block\n",
    "        # batch_size, channels, h, w = out.shape\n",
    "        # in_attn = out.reshape(batch_size, channels, h * w)\n",
    "        # in_attn = self.attention_norm(in_attn)\n",
    "        # in_attn = in_attn.transpose(1, 2)\n",
    "        # out_attn, _ = self.attention(in_attn, in_attn, in_attn)\n",
    "        # out_attn = out_attn.transpose(1, 2).reshape(batch_size, channels, h, w)\n",
    "        # out = out + out_attn\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.down_channels = [32, 64, 128, 256]\n",
    "        self.mid_channels = [256, 256, 128]\n",
    "        self.t_emb_dim = 128\n",
    "        self.down_sample = [True, True, False]\n",
    "        \n",
    "        self.t_proj = nn.Sequential(\n",
    "            nn.Linear(self.t_emb_dim, self.t_emb_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.t_emb_dim, self.t_emb_dim)\n",
    "        )\n",
    "        self.up_sample = list(reversed(self.down_sample))\n",
    "        self.conv_in = nn.Conv2d(in_channels*2, self.down_channels[0], kernel_size=3, padding=1)  # Adjusted for concatenation\n",
    "        \n",
    "        self.downs = nn.ModuleList([])\n",
    "        for i in range(len(self.down_channels) - 1):\n",
    "            self.downs.append(DownBlock(self.down_channels[i], self.down_channels[i+1], self.t_emb_dim,\n",
    "                                        down_sample=self.down_sample[i], num_heads=4))\n",
    "        \n",
    "        self.mids = nn.ModuleList([])\n",
    "        for i in range(len(self.mid_channels) - 1):\n",
    "            self.mids.append(MidBlock(self.mid_channels[i], self.mid_channels[i+1], self.t_emb_dim, num_heads=4))\n",
    "            \n",
    "        self.ups = nn.ModuleList([])\n",
    "        for i in reversed(range(len(self.down_channels) - 1)):\n",
    "            self.ups.append(UpBlock(self.down_channels[i]*2, self.down_channels[i-1] if i != 0 else 16,\n",
    "                                    self.t_emb_dim, up_sample=self.down_sample[i], num_heads=4))\n",
    "        \n",
    "        self.norm_out = nn.GroupNorm(8, 16)\n",
    "        self.conv_out = nn.Conv2d(16, in_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x, cond, t):\n",
    "        x = torch.cat([x, cond], dim=1)  # Concatenate input and conditional image\n",
    "        out = self.conv_in(x)\n",
    "        t_emb = get_time_embedding(t, self.t_emb_dim)\n",
    "        t_emb = self.t_proj(t_emb)\n",
    "        \n",
    "        down_outs = []\n",
    "        for down in self.downs:\n",
    "            down_outs.append(out)\n",
    "            out = down(out, t_emb)\n",
    "        \n",
    "        for mid in self.mids:\n",
    "            out = mid(out, t_emb)\n",
    "            \n",
    "        for up in self.ups:\n",
    "            down_out = down_outs.pop()\n",
    "            out = up(out, down_out, t_emb)\n",
    "        \n",
    "        out = self.norm_out(out)\n",
    "        out = nn.SiLU()(out)\n",
    "        out = self.conv_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training conditional diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"C:/Users/Anirbit/Desktop/MSc/Ind Project/Msc-Project/data\"\n",
    "RESULT_DIR = \"C:/Users/Anirbit/Desktop/MSc/Ind Project/Msc-Project/results\"\n",
    "CKPT_DIR = \"C:/Users/Anirbit/Desktop/MSc/Ind Project/Msc-Project/results/ckpts\"\n",
    "\n",
    "NUM_TIMESTEPS = 1000\n",
    "BETA_START = 0.0001\n",
    "BETA_END = 0.02\n",
    "\n",
    "IN_CHANNELS = 1\n",
    "\n",
    "TASK_NAME = \"conditional_ddpm\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40\n",
    "NUM_SAMPLES = 100\n",
    "NUM_GRID_ROWS = 10\n",
    "LR = 0.0001\n",
    "CKPT_NAME = \"conditional_ddpm_1.pth\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_conditional_ddpm():\n",
    "    # create noise scheduler \n",
    "    print(\"Created Noise Scheduler\")\n",
    "    scheduler = LinearNoiseScheduler(num_timesteps=NUM_TIMESTEPS,\n",
    "                                     beta_start=BETA_START,\n",
    "                                     beta_end=BETA_END, \n",
    "                                     device=device)\n",
    "    \n",
    "    # model\n",
    "    print(\"Created Model\")\n",
    "    model = Unet(in_channels=IN_CHANNELS).to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # Create output dirs\n",
    "    if not os.path.exists(os.path.join(RESULT_DIR, TASK_NAME)):\n",
    "        os.mkdir(os.path.join(RESULT_DIR, TASK_NAME))\n",
    "    \n",
    "    # find checkpoint\n",
    "    if os.path.exists(os.path.join(CKPT_DIR, CKPT_NAME)):\n",
    "        print(\"Loading checkpoint found\")\n",
    "        model.load_state_dict(torch.load(os.path.join(CKPT_DIR, CKPT_NAME), map_location=device))\n",
    "        \n",
    "    # Training params\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"starting epoch: {epoch}\")\n",
    "        losses = []\n",
    "        for img_tensor, cond_tensor in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            print(\"sampling image...\")\n",
    "            img_tensor = img_tensor.float().to(device)\n",
    "            cond_tensor = cond_tensor.float().to(device)\n",
    "            \n",
    "            # sample random noise \n",
    "            print(\"Sampling Noise...\")\n",
    "            noise = torch.randn_like(img_tensor).to(device)\n",
    "            \n",
    "            # sample timestep\n",
    "            print(\"Sampling Timestep...\")\n",
    "            t = torch.randint(0, NUM_TIMESTEPS, (img_tensor.shape[0],)).to(device)\n",
    "            \n",
    "            # Add noise to images according to timestep\n",
    "            print(\"Adding Noise to Image...\")\n",
    "            noisy_img = scheduler.add_noise(img_tensor, noise, t)\n",
    "            print(\"Predicting Noise...\")\n",
    "            noise_pred = model(noisy_img, cond_tensor, t)\n",
    "            \n",
    "            print(\"Calculating Loss in Predicted Noise...\")\n",
    "            loss = criterion(noise_pred, noise)\n",
    "            losses.append(loss.item())\n",
    "            print(\"BackProp...\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f'Finished epoch: {epoch + 1} | Loss: {np.mean(losses)}')\n",
    "        torch.save(model.state_dict(), os.path.join(CKPT_DIR, CKPT_NAME))\n",
    "        \n",
    "    print(\"Done Training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_conditional_ddpm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"C:/Users/Anirbit/Desktop/MSc/Ind Project/Msc-Project/results/ckpts/conditional_ddpm_1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conditional_grid(cond_tensor, nrows=10):\n",
    "    cond_tensor = (cond_tensor + 1) / 2\n",
    "    grid = make_grid(cond_tensor, nrow=nrows)\n",
    "    \n",
    "    grid_img = torchvision.transforms.ToPILImage()(grid)\n",
    "    \n",
    "    grid_img.save(os.path.join(RESULT_DIR, TASK_NAME, \"cond_grid_1.png\"))\n",
    "    grid_img.close()\n",
    "    \n",
    "def sample_n(dataloader, n):\n",
    "    all_data = []\n",
    "    \n",
    "    for img_tensor, cond_tensor in dataloader:\n",
    "        all_data.append((img_tensor, cond_tensor))\n",
    "        \n",
    "    all_data = [(img, cond) for batch in all_data for img, cond in zip(*batch)]\n",
    "    \n",
    "    sampled_data = random.sample(all_data, n)\n",
    "    \n",
    "    sampled_conds = torch.stack([item[1] for item in sampled_data])\n",
    "    \n",
    "    return sampled_conds.float()\n",
    "\n",
    "def sample_conditional(model, scheduler, sampled_conds):\n",
    "    cond_tensor = sampled_conds.to(device)\n",
    "    \n",
    "    xt = torch.randn((NUM_SAMPLES, IN_CHANNELS, 128, 128)).to(device).float()\n",
    "    \n",
    "    for i in tqdm(reversed(range(NUM_TIMESTEPS))):\n",
    "        # xt_cond = torch.cat([xt, cond_tensor], dim=1)\n",
    "        \n",
    "        noise_pred = model(xt, cond_tensor, torch.as_tensor(i).unsqueeze(0).to(device))\n",
    "        \n",
    "        xt, x0_pred = scheduler.sample_prev_timestep(xt, noise_pred, torch.as_tensor(i).to(device))\n",
    "        \n",
    "        ims = torch.clamp(xt, -1., 1.).detach().cpu()\n",
    "        ims = (ims + 1) / 2\n",
    "        grid = make_grid(ims, nrow=NUM_GRID_ROWS)\n",
    "        img = torchvision.transforms.ToPILImage()(grid)\n",
    "        \n",
    "        if not os.path.exists(os.path.join(RESULT_DIR, TASK_NAME, \"samples\")):\n",
    "            os.mkdir(os.path.join(RESULT_DIR, TASK_NAME, \"samples\"))\n",
    "        img.save(os.path.join(RESULT_DIR, TASK_NAME, \"samples\", \"x0_{}.png\".format(i)))\n",
    "        img.close()\n",
    "        \n",
    "def infer_conditional():\n",
    "    model = Unet(in_channels=IN_CHANNELS).to(device)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    scheduler = LinearNoiseScheduler(num_timesteps=NUM_TIMESTEPS,\n",
    "                                     beta_start=BETA_START,\n",
    "                                     beta_end=BETA_END,\n",
    "                                     device=device)\n",
    "    \n",
    "    conditional_imgs = sample_n(test_loader, NUM_SAMPLES)\n",
    "    save_conditional_grid(conditional_imgs)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sample_conditional(model, scheduler, conditional_imgs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [13:28,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "infer_conditional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 22.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as conditional_ddpm_samples.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def numerical_sort(value):\n",
    "    \"\"\" Helper function to extract numerical part from a string and convert to int for sorting. \"\"\"\n",
    "    match = re.search(r'x0_(\\d+)', value)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "def get_sorted_file_list(directory):\n",
    "    \"\"\" Get a sorted list of files based on the numerical part of the filename. \"\"\"\n",
    "    files = [f for f in os.listdir(directory) if f.endswith(\".png\")]\n",
    "    sorted_files = sorted(files, key=numerical_sort, reverse=True)\n",
    "    return sorted_files\n",
    "\n",
    "def add_text_to_image(image, text, position=(50, 50), font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=2, color=(255, 255, 255), thickness=2):\n",
    "    \"\"\" Add text to an image. \"\"\"\n",
    "    cv2.putText(image, text, position, font, font_scale, color, thickness, lineType=cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "\n",
    "def create_video_from_frames(sample_dir, output_name, fps=30):\n",
    "    images = get_sorted_file_list(sample_dir)\n",
    "    \n",
    "    first_im_path = os.path.join(sample_dir, images[0])\n",
    "    frame = cv2.imread(first_im_path)\n",
    "    height, width, channels = frame.shape\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(output_name, fourcc, fps, (width, height))\n",
    "    \n",
    "    for image in tqdm(images):\n",
    "        img_path = os.path.join(sample_dir, image)\n",
    "        frame = cv2.imread(img_path)\n",
    "        \n",
    "        # Add text to the frame\n",
    "        text = str(numerical_sort(image))  # Customize the label text as needed\n",
    "        position = (10, height - 10)  # Position the text at the bottom-left corner\n",
    "        frame = add_text_to_image(frame, text, position)\n",
    "        \n",
    "        video.write(frame)\n",
    "    \n",
    "    video.release()\n",
    "    print(f\"Video saved as {output_name}\")\n",
    "    \n",
    "img_folder = \"C:/Users/Anirbit/Desktop/MSc/Ind Project/Msc-Project/results/conditional_ddpm/samples\"\n",
    "output_video_file = \"conditional_ddpm_samples.mp4\"\n",
    "create_video_from_frames(img_folder, output_video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
